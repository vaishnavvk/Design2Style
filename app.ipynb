{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vaishnavvk/Design2Style/blob/main/app.ipynb)\n",
        "# Design2Style\n",
        "\n",
        "Design2Style: Interactive Clothing Image Generation combines neural style transfer, U2-Net segmentation, and saliency mapping to transform and personalize clothing articles, revolutionizing fashion expression."
      ],
      "metadata": {
        "id": "HIT6LNsZOlOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7XcjKxWOEeRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2054edfb-52c1-4309-a33e-8a81f3dd8b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Path\n",
        "%cd drive/MyDrive/Mini_Project/app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "G62sALx4FeU5",
        "outputId": "8bcd4f53-7a38-47aa-c5ef-318d3cb0f738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Mini_Project/app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edit configurations\n",
        "import torch\n",
        "import albumentations as A\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "CHECKPOINT_DIR = './checkpoints'\n",
        "U2NET_SALIENCY_MAP_CHECKPOINT_FILE = 'u2net.pth'\n",
        "U2NET_CLOTHES_CHECKPOINT_FILE = 'cloth_segm_u2net_latest.pth'\n",
        "\n",
        "ENABLE_STYLE_TRANSFER = True\n",
        "IMG_SIZE = 356\n",
        "ALPHA = 1\n",
        "BETA = 0.01\n",
        "EPOCH_CHECKPOINT = 100\n",
        "\n",
        "basic_transform = A.Compose([\n",
        "    A.Resize(height=IMG_SIZE, width=IMG_SIZE),\n",
        "    A.Normalize(\n",
        "        mean=(.5, .5, .5),\n",
        "        std=(.5, .5, .5),\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C-fb38_wGBNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utilities\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def open_image(path):\n",
        "    return Image.open(path)\n",
        "\n",
        "\n",
        "def load_image(img):\n",
        "    img = open_image(img).convert()\n",
        "    img = basic_transform(image=np.array(img))['image']\n",
        "    img = img.unsqueeze(0)\n",
        "\n",
        "    return img.to(DEVICE)\n",
        "\n",
        "\n",
        "def load_essential_images(original_img, style_img):\n",
        "    original_img = load_image(original_img)\n",
        "    style_img = load_image(style_img)\n",
        "\n",
        "    generated = original_img.clone().requires_grad_(True)\n",
        "\n",
        "    return original_img, style_img, generated\n",
        "\n",
        "\n",
        "def gram_matrix(feature_map):\n",
        "    return feature_map.mm(feature_map.t())\n",
        "\n",
        "\n",
        "def min_max_normalization(d):\n",
        "    return (d - torch.min(d)) / (torch.max(d) - torch.min(d))\n",
        "\n",
        "\n",
        "def checkpoint_exists(filename):\n",
        "    return filename in os.listdir(CHECKPOINT_DIR)\n",
        "\n",
        "\n",
        "def load_vgg_model():\n",
        "    return VGG().to(DEVICE).eval()\n",
        "\n",
        "\n",
        "def load_u2net_model(in_ch=3, out_ch=4, checkpoint=U2NET_CLOTHES_CHECKPOINT_FILE, ordered_dict=True):\n",
        "    model = U2NET(in_ch, out_ch).to(DEVICE)\n",
        "\n",
        "    if checkpoint_exists(checkpoint):\n",
        "        checkpoint = torch.load(\n",
        "            os.path.join(CHECKPOINT_DIR, checkpoint),\n",
        "            map_location=DEVICE\n",
        "        )\n",
        "\n",
        "        if ordered_dict:\n",
        "            state_dict = OrderedDict()\n",
        "\n",
        "            for k, v in checkpoint.items():\n",
        "                name = k[7:]\n",
        "                state_dict[name] = v\n",
        "\n",
        "            model.load_state_dict(state_dict)\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TAfCt7kbGUZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pipelines\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "def to_tensor(array):\n",
        "    return torch.tensor(np.array(array))\n",
        "\n",
        "\n",
        "def style_transfer_pipeline(model, original_img, style_img, EPOCHS, LEARNING_RATE, output_image='generated.png'):\n",
        "    original_img, style_img, generated = load_essential_images(original_img, style_img)\n",
        "\n",
        "    optimizer = optim.Adam([generated], lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(int(EPOCHS)):\n",
        "        generated_features = model(generated)\n",
        "        original_img_features = model(original_img)\n",
        "        style_features = model(style_img)\n",
        "\n",
        "        style_loss = original_loss = 0\n",
        "\n",
        "        for gen_feature, orig_feature, style_feature in zip(generated_features, original_img_features, style_features):\n",
        "            batch_size, channel, height, width = gen_feature.shape\n",
        "\n",
        "            original_loss += torch.mean((gen_feature - orig_feature) ** 2)\n",
        "\n",
        "            G = gram_matrix(gen_feature.view(channel, height * width))\n",
        "            A = gram_matrix(style_feature.view(channel, height * width))\n",
        "\n",
        "            style_loss += torch.mean((G - A) ** 2)\n",
        "\n",
        "        total_loss = ALPHA * original_loss + BETA * style_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch[{epoch}] Total loss = {total_loss}')\n",
        "\n",
        "        if epoch % EPOCH_CHECKPOINT == 0:\n",
        "            save_image(generated, output_image)\n",
        "\n",
        "\n",
        "def segmentation_pipeline(model, original_image, output_image=None):\n",
        "    original_image = basic_transform(image=np.array(open_image(original_image).convert('RGB')))['image']\n",
        "\n",
        "    with torch.no_grad():\n",
        "        p_image = original_image.to(DEVICE).unsqueeze(0)\n",
        "\n",
        "        masks = model(p_image)\n",
        "\n",
        "        masks = torch.max(masks[0], dim=1, keepdim=True)[1]\n",
        "        masks = torch.squeeze(masks, dim=0)\n",
        "        masks = torch.squeeze(masks, dim=0)\n",
        "\n",
        "    masks = masks.cpu().unsqueeze(0)\n",
        "    masks = min_max_normalization(masks).squeeze()\n",
        "\n",
        "    predict_np = masks.numpy() * 255\n",
        "\n",
        "    masks = Image.fromarray(predict_np.astype('uint8')).convert('L')\n",
        "    masks = masks.resize((IMG_SIZE, IMG_SIZE), resample=3)\n",
        "\n",
        "    if output_image is not None:\n",
        "        masks.save(output_image)\n",
        "\n",
        "    return masks\n",
        "\n",
        "\n",
        "def saliency_map_pipeline(model, original_image, output_image='saliency_map.jpg'):\n",
        "    original_image = load_image(original_image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        original_image = original_image.to(DEVICE)\n",
        "        d1, d2, d3, d4, d5, d6, d7 = model(original_image)\n",
        "\n",
        "        pred = d1[:, 0, :, :]\n",
        "\n",
        "    pred = min_max_normalization(pred.cpu()).squeeze()\n",
        "    pred = pred.numpy() * 255\n",
        "\n",
        "    map = Image.fromarray(pred.astype('uint8')).convert('L')\n",
        "    map = map.resize((IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    del d1, d2, d3, d4, d5, d6, d7\n",
        "\n",
        "    if output_image is not None:\n",
        "        map.save(output_image)\n",
        "\n",
        "    return map\n",
        "\n",
        "\n",
        "def merge_images_pipeline(mask, saliency_map, original_image, generated_image, output_image='output.png'):\n",
        "    original_image = open_image(original_image).convert()\n",
        "    original_size = original_image.size\n",
        "    original_image = original_image.resize((IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    generated_image = open_image(generated_image).convert()\n",
        "\n",
        "    merged_image = original_image.copy()\n",
        "\n",
        "    pix_mask = mask.load()\n",
        "    pix_saliency = saliency_map.convert('L').load()\n",
        "    pix_gen = generated_image.load()\n",
        "    pix_seg_gen = merged_image.load()\n",
        "\n",
        "    for x in range(original_image.size[0]):\n",
        "        for y in range(original_image.size[1]):\n",
        "            if pix_mask[x, y] == 255:\n",
        "                if pix_saliency[x, y] == 255:\n",
        "                    pix_seg_gen[x, y] = tuple(int(i) for i in pix_gen[x, y])\n",
        "                else:\n",
        "                    saliency_binary_val = (pix_saliency[x, y] / 255)\n",
        "                    final = tuple((saliency_binary_val * pix_gen[x, y][i] + (1 - saliency_binary_val) * pix_seg_gen[x, y][i]) for i in range(3))\n",
        "\n",
        "                    pix_seg_gen[x, y] = tuple(int(i) for i in final)\n",
        "\n",
        "    merged_image.resize(original_size).save(output_image)\n",
        "    return output_image\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4DZO4NDSGfjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def _upsample_like(src, tar):\n",
        "    src = F.interpolate(src, size=tar.shape[2:], mode='bilinear')\n",
        "\n",
        "    return src\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG, self).__init__()\n",
        "\n",
        "        self.chosen_features = [0, 5, 10, 19, 28]\n",
        "        self.model = models.vgg19(weights='DEFAULT').features[:28]\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "\n",
        "        for idx, layer in enumerate(self.model):\n",
        "            x = layer(x)\n",
        "\n",
        "            if idx in self.chosen_features:\n",
        "                features.append(x)\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=3, dirate=1):\n",
        "        super(REBNCONV, self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(\n",
        "            in_ch,\n",
        "            out_ch,\n",
        "            kernel_size=3,\n",
        "            padding=1 * dirate,\n",
        "            dilation=1 * dirate\n",
        "        )\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "        out = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class RSU7(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))\n",
        "        hx6dup = _upsample_like(hx6d, hx5)\n",
        "\n",
        "        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "class RSU6(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "        hx5d = self.rebnconv5d(torch.cat((hx6, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "class RSU5(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "class RSU4(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "class RSU4F(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d, hx2), 1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d, hx1), 1))\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "class U2NET(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=1):\n",
        "        super(U2NET, self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch, 32, 64)\n",
        "        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64, 32, 128)\n",
        "        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128, 64, 256)\n",
        "        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256, 128, 512)\n",
        "        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512, 256, 512)\n",
        "        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512, 256, 512)\n",
        "\n",
        "        self.stage5d = RSU4F(1024, 256, 512)\n",
        "        self.stage4d = RSU4(1024, 128, 256)\n",
        "        self.stage3d = RSU5(512, 64, 128)\n",
        "        self.stage2d = RSU6(256, 32, 64)\n",
        "        self.stage1d = RSU7(128, 16, 64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
        "        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
        "        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)\n",
        "        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)\n",
        "        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
        "        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6 * out_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hx = x\n",
        "\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = _upsample_like(hx6, hx5)\n",
        "\n",
        "        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = _upsample_like(d2, d1)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = _upsample_like(d3, d1)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = _upsample_like(d4, d1)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = _upsample_like(d5, d1)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = _upsample_like(d6, d1)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))\n",
        "\n",
        "        return d0, d1, d2, d3, d4, d5, d6\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "66dtQk9NGhxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install gradio\n",
        "!pip install gradio"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EOOUGu3sJEvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "content_image = './examples/dress.jpg'\n",
        "style_image = './examples/style.jpg'\n",
        "generated_image = './examples/generated.png'\n",
        "output_image = './examples/output.png'\n",
        "saliency_image = './examples/saliency_map.jpg'\n",
        "mask_image = './examples/mask.jpg'\n",
        "\n",
        "content_image = gr.inputs.Image(label=\"Upload Cloth Image\", type=\"filepath\")\n",
        "style_image = gr.inputs.Image(label=\"Upload Style Image\",type=\"filepath\")\n",
        "\n",
        "lr_slider = gr.inputs.Slider(0.001, 0.1, label=\"Adjust Learning Rate\" , default=0.01, step=0.001)\n",
        "epoch_slider = gr.inputs.Slider(100, 1000, label=\"Number of epochs\" , default=100,step=50,)\n",
        "\n",
        "\n",
        "def perform_design_transfer(content_image, style_image, lr, epochs):\n",
        "    if ENABLE_STYLE_TRANSFER:\n",
        "        style_transfer_pipeline(load_vgg_model(), content_image, style_image, int(epochs), lr, output_image=generated_image)\n",
        "\n",
        "    mask = segmentation_pipeline(load_u2net_model(), content_image, output_image=mask_image)\n",
        "    saliency_map = saliency_map_pipeline(\n",
        "        load_u2net_model(out_ch=1, checkpoint=U2NET_SALIENCY_MAP_CHECKPOINT_FILE, ordered_dict=False),\n",
        "        content_image,\n",
        "        output_image=saliency_image\n",
        "    )\n",
        "    output = merge_images_pipeline(mask, saliency_map, content_image, generated_image, output_image=output_image)\n",
        "    return output\n",
        "\n",
        "merged_image =  gr.outputs.Image(label = \"Output\",type=\"filepath\").style(height=500)\n",
        "\n",
        "example1 = ['./examples/example-1/dress.jpg', './examples/example-1/style.jpg']\n",
        "example2 = ['./examples/example-2/dress.jpg', './examples/example-2/style.jpg']\n",
        "\n",
        "app_interface = gr.Interface(fn=perform_design_transfer,\n",
        "                             inputs=[content_image,\n",
        "                                     style_image,\n",
        "                                     lr_slider,\n",
        "                                     epoch_slider,\n",
        "                                     ],\n",
        "                             outputs=merged_image,\n",
        "                             examples=[example1, example2],\n",
        "                             title=\"Design2Style\",\n",
        "                             description=\"Interactive Clothing Image Generation combines neural style transfer, U2-Net segmentation, and saliency mapping to transform and personalize clothing articles.\"\n",
        "                             )\n",
        "\n",
        "app_interface.queue().launch(debug=True,share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sigj-xXHGpAv",
        "outputId": "da071b6f-70a3-4519-fe57-f50fe3a3f4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:259: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:262: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:89: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:93: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:43: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/image.py:390: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://889cdf3423a3ba104b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://889cdf3423a3ba104b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0] Total loss = 9824051.0\n",
            "Epoch[1] Total loss = 9431073.0\n",
            "Epoch[2] Total loss = 8906381.0\n",
            "Epoch[3] Total loss = 8317710.5\n",
            "Epoch[4] Total loss = 7717464.5\n",
            "Epoch[5] Total loss = 7148005.5\n",
            "Epoch[6] Total loss = 6644780.5\n",
            "Epoch[7] Total loss = 6209053.5\n",
            "Epoch[8] Total loss = 5815017.5\n",
            "Epoch[9] Total loss = 5447209.5\n",
            "Epoch[10] Total loss = 5112764.5\n",
            "Epoch[11] Total loss = 4824786.5\n",
            "Epoch[12] Total loss = 4585852.0\n",
            "Epoch[13] Total loss = 4388284.0\n",
            "Epoch[14] Total loss = 4221011.5\n",
            "Epoch[15] Total loss = 4074113.0\n",
            "Epoch[16] Total loss = 3941601.0\n",
            "Epoch[17] Total loss = 3820402.75\n",
            "Epoch[18] Total loss = 3709091.25\n",
            "Epoch[19] Total loss = 3606762.75\n",
            "Epoch[20] Total loss = 3512101.75\n",
            "Epoch[21] Total loss = 3423551.5\n",
            "Epoch[22] Total loss = 3339463.25\n",
            "Epoch[23] Total loss = 3258582.75\n",
            "Epoch[24] Total loss = 3180203.5\n",
            "Epoch[25] Total loss = 3104051.0\n",
            "Epoch[26] Total loss = 3029819.25\n",
            "Epoch[27] Total loss = 2957291.25\n",
            "Epoch[28] Total loss = 2886225.0\n",
            "Epoch[29] Total loss = 2816373.5\n",
            "Epoch[30] Total loss = 2747508.25\n",
            "Epoch[31] Total loss = 2679653.0\n",
            "Epoch[32] Total loss = 2612920.0\n",
            "Epoch[33] Total loss = 2547374.75\n",
            "Epoch[34] Total loss = 2483132.25\n",
            "Epoch[35] Total loss = 2420268.25\n",
            "Epoch[36] Total loss = 2358794.0\n",
            "Epoch[37] Total loss = 2298631.25\n",
            "Epoch[38] Total loss = 2239661.0\n",
            "Epoch[39] Total loss = 2181857.25\n",
            "Epoch[40] Total loss = 2125196.5\n",
            "Epoch[41] Total loss = 2069636.625\n",
            "Epoch[42] Total loss = 2015166.875\n",
            "Epoch[43] Total loss = 1961794.75\n",
            "Epoch[44] Total loss = 1909493.125\n",
            "Epoch[45] Total loss = 1858295.0\n",
            "Epoch[46] Total loss = 1808213.375\n",
            "Epoch[47] Total loss = 1759271.125\n",
            "Epoch[48] Total loss = 1711491.375\n",
            "Epoch[49] Total loss = 1664901.625\n",
            "Epoch[50] Total loss = 1619526.625\n",
            "Epoch[51] Total loss = 1575367.375\n",
            "Epoch[52] Total loss = 1532447.75\n",
            "Epoch[53] Total loss = 1490798.25\n",
            "Epoch[54] Total loss = 1450439.375\n",
            "Epoch[55] Total loss = 1411383.25\n",
            "Epoch[56] Total loss = 1373654.625\n",
            "Epoch[57] Total loss = 1337258.375\n",
            "Epoch[58] Total loss = 1302204.875\n",
            "Epoch[59] Total loss = 1268504.75\n",
            "Epoch[60] Total loss = 1236162.5\n",
            "Epoch[61] Total loss = 1205187.25\n",
            "Epoch[62] Total loss = 1175579.875\n",
            "Epoch[63] Total loss = 1147324.25\n",
            "Epoch[64] Total loss = 1120397.125\n",
            "Epoch[65] Total loss = 1094786.875\n",
            "Epoch[66] Total loss = 1070470.875\n",
            "Epoch[67] Total loss = 1047422.9375\n",
            "Epoch[68] Total loss = 1025626.5625\n",
            "Epoch[69] Total loss = 1005048.0\n",
            "Epoch[70] Total loss = 985644.0625\n",
            "Epoch[71] Total loss = 967373.1875\n",
            "Epoch[72] Total loss = 950188.6875\n",
            "Epoch[73] Total loss = 934048.75\n",
            "Epoch[74] Total loss = 918904.375\n",
            "Epoch[75] Total loss = 904700.4375\n",
            "Epoch[76] Total loss = 891384.625\n",
            "Epoch[77] Total loss = 878900.6875\n",
            "Epoch[78] Total loss = 867195.9375\n",
            "Epoch[79] Total loss = 856215.875\n",
            "Epoch[80] Total loss = 845905.4375\n",
            "Epoch[81] Total loss = 836212.5625\n",
            "Epoch[82] Total loss = 827084.375\n",
            "Epoch[83] Total loss = 818470.375\n",
            "Epoch[84] Total loss = 810323.25\n",
            "Epoch[85] Total loss = 802597.375\n",
            "Epoch[86] Total loss = 795252.1875\n",
            "Epoch[87] Total loss = 788250.0\n",
            "Epoch[88] Total loss = 781552.0\n",
            "Epoch[89] Total loss = 775126.0625\n",
            "Epoch[90] Total loss = 768937.25\n",
            "Epoch[91] Total loss = 762960.1875\n",
            "Epoch[92] Total loss = 757171.125\n",
            "Epoch[93] Total loss = 751548.125\n",
            "Epoch[94] Total loss = 746073.625\n",
            "Epoch[95] Total loss = 740727.3125\n",
            "Epoch[96] Total loss = 735495.3125\n",
            "Epoch[97] Total loss = 730366.8125\n",
            "Epoch[98] Total loss = 725333.375\n",
            "Epoch[99] Total loss = 720383.375\n",
            "Epoch[0] Total loss = 9824051.0\n",
            "Epoch[1] Total loss = 9431073.0\n",
            "Epoch[2] Total loss = 8906381.0\n",
            "Epoch[3] Total loss = 8317711.5\n",
            "Epoch[4] Total loss = 7717463.5\n",
            "Epoch[5] Total loss = 7148007.5\n",
            "Epoch[6] Total loss = 6644775.5\n",
            "Epoch[7] Total loss = 6209047.5\n",
            "Epoch[8] Total loss = 5815012.5\n",
            "Epoch[9] Total loss = 5447205.5\n",
            "Epoch[10] Total loss = 5112759.0\n",
            "Epoch[11] Total loss = 4824784.5\n",
            "Epoch[12] Total loss = 4585847.0\n",
            "Epoch[13] Total loss = 4388270.5\n",
            "Epoch[14] Total loss = 4221008.0\n",
            "Epoch[15] Total loss = 4074109.5\n",
            "Epoch[16] Total loss = 3941592.25\n",
            "Epoch[17] Total loss = 3820407.75\n",
            "Epoch[18] Total loss = 3709119.75\n",
            "Epoch[19] Total loss = 3606805.5\n",
            "Epoch[20] Total loss = 3512133.75\n",
            "Epoch[21] Total loss = 3423570.5\n",
            "Epoch[22] Total loss = 3339474.75\n",
            "Epoch[23] Total loss = 3258601.0\n",
            "Epoch[24] Total loss = 3180238.5\n",
            "Epoch[25] Total loss = 3104107.25\n",
            "Epoch[26] Total loss = 3029887.5\n",
            "Epoch[27] Total loss = 2957368.75\n",
            "Epoch[28] Total loss = 2886284.75\n",
            "Epoch[29] Total loss = 2816430.0\n",
            "Epoch[30] Total loss = 2747555.25\n",
            "Epoch[31] Total loss = 2679714.0\n",
            "Epoch[32] Total loss = 2612992.25\n",
            "Epoch[33] Total loss = 2547436.0\n",
            "Epoch[34] Total loss = 2483187.0\n",
            "Epoch[35] Total loss = 2420319.25\n",
            "Epoch[36] Total loss = 2358824.0\n",
            "Epoch[37] Total loss = 2298646.75\n",
            "Epoch[38] Total loss = 2239676.25\n",
            "Epoch[39] Total loss = 2181870.75\n",
            "Epoch[40] Total loss = 2125199.25\n",
            "Epoch[41] Total loss = 2069641.5\n",
            "Epoch[42] Total loss = 2015171.125\n",
            "Epoch[43] Total loss = 1961794.125\n",
            "Epoch[44] Total loss = 1909497.5\n",
            "Epoch[45] Total loss = 1858294.75\n",
            "Epoch[46] Total loss = 1808215.375\n",
            "Epoch[47] Total loss = 1759262.75\n",
            "Epoch[48] Total loss = 1711474.375\n",
            "Epoch[49] Total loss = 1664879.625\n",
            "Epoch[50] Total loss = 1619495.0\n",
            "Epoch[51] Total loss = 1575326.375\n",
            "Epoch[52] Total loss = 1532404.5\n",
            "Epoch[53] Total loss = 1490750.0\n",
            "Epoch[54] Total loss = 1450385.75\n",
            "Epoch[55] Total loss = 1411332.75\n",
            "Epoch[56] Total loss = 1373608.75\n",
            "Epoch[57] Total loss = 1337216.625\n",
            "Epoch[58] Total loss = 1302171.25\n",
            "Epoch[59] Total loss = 1268485.0\n",
            "Epoch[60] Total loss = 1236152.5\n",
            "Epoch[61] Total loss = 1205185.375\n",
            "Epoch[62] Total loss = 1175582.25\n",
            "Epoch[63] Total loss = 1147323.75\n",
            "Epoch[64] Total loss = 1120394.75\n",
            "Epoch[65] Total loss = 1094779.0\n",
            "Epoch[66] Total loss = 1070461.0\n",
            "Epoch[67] Total loss = 1047410.875\n",
            "Epoch[68] Total loss = 1025605.625\n",
            "Epoch[69] Total loss = 1005018.5625\n",
            "Epoch[70] Total loss = 985610.625\n",
            "Epoch[71] Total loss = 967337.3125\n",
            "Epoch[72] Total loss = 950154.4375\n",
            "Epoch[73] Total loss = 934011.9375\n",
            "Epoch[74] Total loss = 918866.75\n",
            "Epoch[75] Total loss = 904663.4375\n",
            "Epoch[76] Total loss = 891347.4375\n",
            "Epoch[77] Total loss = 878862.375\n",
            "Epoch[78] Total loss = 867156.1875\n",
            "Epoch[79] Total loss = 856174.5625\n",
            "Epoch[80] Total loss = 845864.0625\n",
            "Epoch[81] Total loss = 836171.125\n",
            "Epoch[82] Total loss = 827045.3125\n",
            "Epoch[83] Total loss = 818434.375\n",
            "Epoch[84] Total loss = 810287.625\n",
            "Epoch[85] Total loss = 802560.375\n",
            "Epoch[86] Total loss = 795209.125\n",
            "Epoch[87] Total loss = 788197.4375\n",
            "Epoch[88] Total loss = 781492.4375\n",
            "Epoch[89] Total loss = 775062.375\n",
            "Epoch[90] Total loss = 768874.9375\n",
            "Epoch[91] Total loss = 762901.8125\n",
            "Epoch[92] Total loss = 757116.0625\n",
            "Epoch[93] Total loss = 751498.4375\n",
            "Epoch[94] Total loss = 746025.0\n",
            "Epoch[95] Total loss = 740683.6875\n",
            "Epoch[96] Total loss = 735457.5\n",
            "Epoch[97] Total loss = 730332.5\n",
            "Epoch[98] Total loss = 725299.25\n",
            "Epoch[99] Total loss = 720349.1875\n",
            "Epoch[100] Total loss = 715475.0625\n",
            "Epoch[101] Total loss = 710670.5\n",
            "Epoch[102] Total loss = 705931.8125\n",
            "Epoch[103] Total loss = 701256.3125\n",
            "Epoch[104] Total loss = 696638.125\n",
            "Epoch[105] Total loss = 692074.8125\n",
            "Epoch[106] Total loss = 687565.3125\n",
            "Epoch[107] Total loss = 683107.625\n",
            "Epoch[108] Total loss = 678702.6875\n",
            "Epoch[109] Total loss = 674348.75\n",
            "Epoch[110] Total loss = 670042.0625\n",
            "Epoch[111] Total loss = 665781.9375\n",
            "Epoch[112] Total loss = 661569.5625\n",
            "Epoch[113] Total loss = 657402.3125\n",
            "Epoch[114] Total loss = 653279.3125\n",
            "Epoch[115] Total loss = 649200.0\n",
            "Epoch[116] Total loss = 645163.6875\n",
            "Epoch[117] Total loss = 641167.625\n",
            "Epoch[118] Total loss = 637211.9375\n",
            "Epoch[119] Total loss = 633296.25\n",
            "Epoch[120] Total loss = 629418.75\n",
            "Epoch[121] Total loss = 625578.125\n",
            "Epoch[122] Total loss = 621774.6875\n",
            "Epoch[123] Total loss = 618006.125\n",
            "Epoch[124] Total loss = 614270.75\n",
            "Epoch[125] Total loss = 610568.75\n",
            "Epoch[126] Total loss = 606899.5\n",
            "Epoch[127] Total loss = 603261.5\n",
            "Epoch[128] Total loss = 599653.6875\n",
            "Epoch[129] Total loss = 596076.0\n",
            "Epoch[130] Total loss = 592527.4375\n",
            "Epoch[131] Total loss = 589008.5625\n",
            "Epoch[132] Total loss = 585519.5\n",
            "Epoch[133] Total loss = 582057.0\n",
            "Epoch[134] Total loss = 578620.5625\n",
            "Epoch[135] Total loss = 575209.1875\n",
            "Epoch[136] Total loss = 571823.0\n",
            "Epoch[137] Total loss = 568462.125\n",
            "Epoch[138] Total loss = 565124.375\n",
            "Epoch[139] Total loss = 561809.8125\n",
            "Epoch[140] Total loss = 558519.125\n",
            "Epoch[141] Total loss = 555251.375\n",
            "Epoch[142] Total loss = 552006.375\n",
            "Epoch[143] Total loss = 548784.0\n",
            "Epoch[144] Total loss = 545583.125\n",
            "Epoch[145] Total loss = 542404.625\n",
            "Epoch[146] Total loss = 539247.5\n",
            "Epoch[147] Total loss = 536111.5\n",
            "Epoch[148] Total loss = 532996.3125\n",
            "Epoch[149] Total loss = 529901.0625\n",
            "Epoch[150] Total loss = 526825.625\n",
            "Epoch[151] Total loss = 523770.03125\n",
            "Epoch[152] Total loss = 520734.03125\n",
            "Epoch[153] Total loss = 517718.28125\n",
            "Epoch[154] Total loss = 514722.46875\n",
            "Epoch[155] Total loss = 511745.59375\n",
            "Epoch[156] Total loss = 508788.40625\n",
            "Epoch[157] Total loss = 505849.75\n",
            "Epoch[158] Total loss = 502930.40625\n",
            "Epoch[159] Total loss = 500029.78125\n",
            "Epoch[160] Total loss = 497147.5625\n",
            "Epoch[161] Total loss = 494283.65625\n",
            "Epoch[162] Total loss = 491438.65625\n",
            "Epoch[163] Total loss = 488611.875\n",
            "Epoch[164] Total loss = 485804.125\n",
            "Epoch[165] Total loss = 483015.1875\n",
            "Epoch[166] Total loss = 480245.15625\n",
            "Epoch[167] Total loss = 477493.75\n",
            "Epoch[168] Total loss = 474761.375\n",
            "Epoch[169] Total loss = 472047.375\n",
            "Epoch[170] Total loss = 469350.78125\n",
            "Epoch[171] Total loss = 466671.78125\n",
            "Epoch[172] Total loss = 464010.125\n",
            "Epoch[173] Total loss = 461365.78125\n",
            "Epoch[174] Total loss = 458738.96875\n",
            "Epoch[175] Total loss = 456129.53125\n",
            "Epoch[176] Total loss = 453537.125\n",
            "Epoch[177] Total loss = 450962.15625\n",
            "Epoch[178] Total loss = 448404.65625\n",
            "Epoch[179] Total loss = 445864.3125\n",
            "Epoch[180] Total loss = 443342.15625\n",
            "Epoch[181] Total loss = 440836.71875\n",
            "Epoch[182] Total loss = 438348.125\n",
            "Epoch[183] Total loss = 435876.0625\n",
            "Epoch[184] Total loss = 433421.75\n",
            "Epoch[185] Total loss = 430984.59375\n",
            "Epoch[186] Total loss = 428564.625\n",
            "Epoch[187] Total loss = 426161.5\n",
            "Epoch[188] Total loss = 423775.125\n",
            "Epoch[189] Total loss = 421405.625\n",
            "Epoch[190] Total loss = 419053.28125\n",
            "Epoch[191] Total loss = 416717.65625\n",
            "Epoch[192] Total loss = 414398.21875\n",
            "Epoch[193] Total loss = 412095.25\n",
            "Epoch[194] Total loss = 409808.5\n",
            "Epoch[195] Total loss = 407537.90625\n",
            "Epoch[196] Total loss = 405284.03125\n",
            "Epoch[197] Total loss = 403046.1875\n",
            "Epoch[198] Total loss = 400825.125\n",
            "Epoch[199] Total loss = 398620.84375\n",
            "Epoch[0] Total loss = 9824051.0\n",
            "Epoch[1] Total loss = 9787945.0\n",
            "Epoch[2] Total loss = 9750861.0\n",
            "Epoch[3] Total loss = 9712494.0\n",
            "Epoch[4] Total loss = 9672461.0\n",
            "Epoch[5] Total loss = 9630437.0\n",
            "Epoch[6] Total loss = 9586090.0\n",
            "Epoch[7] Total loss = 9539216.0\n",
            "Epoch[8] Total loss = 9489723.0\n",
            "Epoch[9] Total loss = 9437552.0\n",
            "Epoch[10] Total loss = 9382700.0\n",
            "Epoch[11] Total loss = 9325301.0\n",
            "Epoch[12] Total loss = 9265516.0\n",
            "Epoch[13] Total loss = 9203521.0\n",
            "Epoch[14] Total loss = 9139589.0\n",
            "Epoch[15] Total loss = 9073997.0\n",
            "Epoch[16] Total loss = 9006908.0\n",
            "Epoch[17] Total loss = 8938567.0\n",
            "Epoch[18] Total loss = 8869236.0\n",
            "Epoch[19] Total loss = 8799058.0\n",
            "Epoch[20] Total loss = 8728134.0\n",
            "Epoch[21] Total loss = 8656580.0\n",
            "Epoch[22] Total loss = 8584488.0\n",
            "Epoch[23] Total loss = 8511943.0\n",
            "Epoch[24] Total loss = 8439094.0\n",
            "Epoch[25] Total loss = 8366020.0\n",
            "Epoch[26] Total loss = 8292813.0\n",
            "Epoch[27] Total loss = 8219511.5\n",
            "Epoch[28] Total loss = 8146235.5\n",
            "Epoch[29] Total loss = 8073042.5\n",
            "Epoch[30] Total loss = 7999986.5\n",
            "Epoch[31] Total loss = 7927156.0\n",
            "Epoch[32] Total loss = 7854552.5\n",
            "Epoch[33] Total loss = 7782205.5\n",
            "Epoch[34] Total loss = 7710139.5\n",
            "Epoch[35] Total loss = 7638419.0\n",
            "Epoch[36] Total loss = 7567060.0\n",
            "Epoch[37] Total loss = 7496115.0\n",
            "Epoch[38] Total loss = 7425607.5\n",
            "Epoch[39] Total loss = 7355568.0\n",
            "Epoch[40] Total loss = 7286032.0\n",
            "Epoch[41] Total loss = 7217018.5\n",
            "Epoch[42] Total loss = 7148515.5\n",
            "Epoch[43] Total loss = 7080545.5\n",
            "Epoch[44] Total loss = 7013114.5\n",
            "Epoch[45] Total loss = 6946255.0\n",
            "Epoch[46] Total loss = 6880021.0\n",
            "Epoch[47] Total loss = 6814412.5\n",
            "Epoch[48] Total loss = 6749474.0\n",
            "Epoch[49] Total loss = 6685228.5\n",
            "Epoch[50] Total loss = 6621683.0\n",
            "Epoch[51] Total loss = 6558866.0\n",
            "Epoch[52] Total loss = 6496796.5\n",
            "Epoch[53] Total loss = 6435516.5\n",
            "Epoch[54] Total loss = 6375042.5\n",
            "Epoch[55] Total loss = 6315388.5\n",
            "Epoch[56] Total loss = 6256571.0\n",
            "Epoch[57] Total loss = 6198633.5\n",
            "Epoch[58] Total loss = 6141593.0\n",
            "Epoch[59] Total loss = 6085470.0\n",
            "Epoch[60] Total loss = 6030260.5\n",
            "Epoch[61] Total loss = 5975991.5\n",
            "Epoch[62] Total loss = 5922665.5\n",
            "Epoch[63] Total loss = 5870281.0\n",
            "Epoch[64] Total loss = 5818836.0\n",
            "Epoch[65] Total loss = 5768359.5\n",
            "Epoch[66] Total loss = 5718823.5\n",
            "Epoch[67] Total loss = 5670220.5\n",
            "Epoch[68] Total loss = 5622552.0\n",
            "Epoch[69] Total loss = 5575802.0\n",
            "Epoch[70] Total loss = 5529990.0\n",
            "Epoch[71] Total loss = 5485107.0\n",
            "Epoch[72] Total loss = 5441119.0\n",
            "Epoch[73] Total loss = 5398007.5\n",
            "Epoch[74] Total loss = 5355775.0\n",
            "Epoch[75] Total loss = 5314397.5\n",
            "Epoch[76] Total loss = 5273876.5\n",
            "Epoch[77] Total loss = 5234189.5\n",
            "Epoch[78] Total loss = 5195320.5\n",
            "Epoch[79] Total loss = 5157278.0\n",
            "Epoch[80] Total loss = 5120039.5\n",
            "Epoch[81] Total loss = 5083576.5\n",
            "Epoch[82] Total loss = 5047869.0\n",
            "Epoch[83] Total loss = 5012909.5\n",
            "Epoch[84] Total loss = 4978678.5\n",
            "Epoch[85] Total loss = 4945165.5\n",
            "Epoch[86] Total loss = 4912353.0\n",
            "Epoch[87] Total loss = 4880218.0\n",
            "Epoch[88] Total loss = 4848747.5\n",
            "Epoch[89] Total loss = 4817941.5\n",
            "Epoch[90] Total loss = 4787768.5\n",
            "Epoch[91] Total loss = 4758219.0\n",
            "Epoch[92] Total loss = 4729287.0\n",
            "Epoch[93] Total loss = 4700944.5\n",
            "Epoch[94] Total loss = 4673164.5\n",
            "Epoch[95] Total loss = 4645946.0\n",
            "Epoch[96] Total loss = 4619261.5\n",
            "Epoch[97] Total loss = 4593089.5\n",
            "Epoch[98] Total loss = 4567420.0\n",
            "Epoch[99] Total loss = 4542244.0\n",
            "Epoch[100] Total loss = 4517558.5\n",
            "Epoch[101] Total loss = 4493342.0\n",
            "Epoch[102] Total loss = 4469580.5\n",
            "Epoch[103] Total loss = 4446270.0\n",
            "Epoch[104] Total loss = 4423391.5\n",
            "Epoch[105] Total loss = 4400926.5\n",
            "Epoch[106] Total loss = 4378876.5\n",
            "Epoch[107] Total loss = 4357226.5\n",
            "Epoch[108] Total loss = 4335954.5\n",
            "Epoch[109] Total loss = 4315046.5\n",
            "Epoch[110] Total loss = 4294492.5\n",
            "Epoch[111] Total loss = 4274294.0\n",
            "Epoch[112] Total loss = 4254427.5\n",
            "Epoch[113] Total loss = 4234889.5\n",
            "Epoch[114] Total loss = 4215678.5\n",
            "Epoch[115] Total loss = 4196784.0\n",
            "Epoch[116] Total loss = 4178187.75\n",
            "Epoch[117] Total loss = 4159885.25\n",
            "Epoch[118] Total loss = 4141868.5\n",
            "Epoch[119] Total loss = 4124123.75\n",
            "Epoch[120] Total loss = 4106648.25\n",
            "Epoch[121] Total loss = 4089441.75\n",
            "Epoch[122] Total loss = 4072492.25\n",
            "Epoch[123] Total loss = 4055797.25\n",
            "Epoch[124] Total loss = 4039343.0\n",
            "Epoch[125] Total loss = 4023125.5\n",
            "Epoch[126] Total loss = 4007134.25\n",
            "Epoch[127] Total loss = 3991360.75\n",
            "Epoch[128] Total loss = 3975805.25\n",
            "Epoch[129] Total loss = 3960457.0\n",
            "Epoch[130] Total loss = 3945306.75\n",
            "Epoch[131] Total loss = 3930356.25\n",
            "Epoch[132] Total loss = 3915596.5\n",
            "Epoch[133] Total loss = 3901023.75\n",
            "Epoch[134] Total loss = 3886644.25\n",
            "Epoch[135] Total loss = 3872444.5\n",
            "Epoch[136] Total loss = 3858417.25\n",
            "Epoch[137] Total loss = 3844557.75\n",
            "Epoch[138] Total loss = 3830857.25\n",
            "Epoch[139] Total loss = 3817318.0\n",
            "Epoch[140] Total loss = 3803935.25\n",
            "Epoch[141] Total loss = 3790707.75\n",
            "Epoch[142] Total loss = 3777627.25\n",
            "Epoch[143] Total loss = 3764682.25\n",
            "Epoch[144] Total loss = 3751873.25\n",
            "Epoch[145] Total loss = 3739196.75\n",
            "Epoch[146] Total loss = 3726652.75\n",
            "Epoch[147] Total loss = 3714235.5\n",
            "Epoch[148] Total loss = 3701943.25\n",
            "Epoch[149] Total loss = 3689767.25\n",
            "Epoch[150] Total loss = 3677712.25\n",
            "Epoch[151] Total loss = 3665767.25\n",
            "Epoch[152] Total loss = 3653930.5\n",
            "Epoch[153] Total loss = 3642204.0\n",
            "Epoch[154] Total loss = 3630585.75\n",
            "Epoch[155] Total loss = 3619073.75\n",
            "Epoch[156] Total loss = 3607662.5\n",
            "Epoch[157] Total loss = 3596351.0\n",
            "Epoch[158] Total loss = 3585134.0\n",
            "Epoch[159] Total loss = 3574011.5\n",
            "Epoch[160] Total loss = 3562979.75\n",
            "Epoch[161] Total loss = 3552034.75\n",
            "Epoch[162] Total loss = 3541175.25\n",
            "Epoch[163] Total loss = 3530399.25\n",
            "Epoch[164] Total loss = 3519703.5\n",
            "Epoch[165] Total loss = 3509085.75\n",
            "Epoch[166] Total loss = 3498550.25\n",
            "Epoch[167] Total loss = 3488089.5\n",
            "Epoch[168] Total loss = 3477702.25\n",
            "Epoch[169] Total loss = 3467386.25\n",
            "Epoch[170] Total loss = 3457139.25\n",
            "Epoch[171] Total loss = 3446959.5\n",
            "Epoch[172] Total loss = 3436845.75\n",
            "Epoch[173] Total loss = 3426800.75\n",
            "Epoch[174] Total loss = 3416822.5\n",
            "Epoch[175] Total loss = 3406903.5\n",
            "Epoch[176] Total loss = 3397044.5\n",
            "Epoch[177] Total loss = 3387244.5\n",
            "Epoch[178] Total loss = 3377504.75\n",
            "Epoch[179] Total loss = 3367824.0\n",
            "Epoch[180] Total loss = 3358202.25\n",
            "Epoch[181] Total loss = 3348638.25\n",
            "Epoch[182] Total loss = 3339129.25\n",
            "Epoch[183] Total loss = 3329672.75\n",
            "Epoch[184] Total loss = 3320267.25\n",
            "Epoch[185] Total loss = 3310911.0\n",
            "Epoch[186] Total loss = 3301600.25\n",
            "Epoch[187] Total loss = 3292337.0\n",
            "Epoch[188] Total loss = 3283121.25\n",
            "Epoch[189] Total loss = 3273949.0\n",
            "Epoch[190] Total loss = 3264818.5\n",
            "Epoch[191] Total loss = 3255728.5\n",
            "Epoch[192] Total loss = 3246679.25\n",
            "Epoch[193] Total loss = 3237671.25\n",
            "Epoch[194] Total loss = 3228704.0\n",
            "Epoch[195] Total loss = 3219777.5\n",
            "Epoch[196] Total loss = 3210893.5\n",
            "Epoch[197] Total loss = 3202047.0\n",
            "Epoch[198] Total loss = 3193238.0\n",
            "Epoch[199] Total loss = 3184466.0\n",
            "Epoch[200] Total loss = 3175727.0\n",
            "Epoch[201] Total loss = 3167022.0\n",
            "Epoch[202] Total loss = 3158350.5\n",
            "Epoch[203] Total loss = 3149711.0\n",
            "Epoch[204] Total loss = 3141109.0\n",
            "Epoch[205] Total loss = 3132544.0\n",
            "Epoch[206] Total loss = 3124011.75\n",
            "Epoch[207] Total loss = 3115512.5\n",
            "Epoch[208] Total loss = 3107040.75\n",
            "Epoch[209] Total loss = 3098597.75\n",
            "Epoch[210] Total loss = 3090184.5\n",
            "Epoch[211] Total loss = 3081799.5\n",
            "Epoch[212] Total loss = 3073441.75\n",
            "Epoch[213] Total loss = 3065111.25\n",
            "Epoch[214] Total loss = 3056806.75\n",
            "Epoch[215] Total loss = 3048529.75\n",
            "Epoch[216] Total loss = 3040279.0\n",
            "Epoch[217] Total loss = 3032055.25\n",
            "Epoch[218] Total loss = 3023860.0\n",
            "Epoch[219] Total loss = 3015692.0\n",
            "Epoch[220] Total loss = 3007550.75\n",
            "Epoch[221] Total loss = 2999433.5\n",
            "Epoch[222] Total loss = 2991341.25\n",
            "Epoch[223] Total loss = 2983274.5\n",
            "Epoch[224] Total loss = 2975230.0\n",
            "Epoch[225] Total loss = 2967208.75\n",
            "Epoch[226] Total loss = 2959210.5\n",
            "Epoch[227] Total loss = 2951234.5\n",
            "Epoch[228] Total loss = 2943280.25\n",
            "Epoch[229] Total loss = 2935348.0\n",
            "Epoch[230] Total loss = 2927438.0\n",
            "Epoch[231] Total loss = 2919549.0\n",
            "Epoch[232] Total loss = 2911680.25\n",
            "Epoch[233] Total loss = 2903833.25\n",
            "Epoch[234] Total loss = 2896005.25\n",
            "Epoch[235] Total loss = 2888197.5\n",
            "Epoch[236] Total loss = 2880410.75\n",
            "Epoch[237] Total loss = 2872642.75\n",
            "Epoch[238] Total loss = 2864893.5\n",
            "Epoch[239] Total loss = 2857161.5\n",
            "Epoch[240] Total loss = 2849446.25\n",
            "Epoch[241] Total loss = 2841750.25\n",
            "Epoch[242] Total loss = 2834072.75\n",
            "Epoch[243] Total loss = 2826412.75\n",
            "Epoch[244] Total loss = 2818769.75\n",
            "Epoch[245] Total loss = 2811144.25\n",
            "Epoch[246] Total loss = 2803535.25\n",
            "Epoch[247] Total loss = 2795943.0\n",
            "Epoch[248] Total loss = 2788366.5\n",
            "Epoch[249] Total loss = 2780807.5\n",
            "Epoch[250] Total loss = 2773264.25\n",
            "Epoch[251] Total loss = 2765738.0\n",
            "Epoch[252] Total loss = 2758228.25\n",
            "Epoch[253] Total loss = 2750735.75\n",
            "Epoch[254] Total loss = 2743260.25\n",
            "Epoch[255] Total loss = 2735799.5\n",
            "Epoch[256] Total loss = 2728355.0\n",
            "Epoch[257] Total loss = 2720927.25\n",
            "Epoch[258] Total loss = 2713513.5\n",
            "Epoch[259] Total loss = 2706113.5\n",
            "Epoch[260] Total loss = 2698729.0\n",
            "Epoch[261] Total loss = 2691362.0\n",
            "Epoch[262] Total loss = 2684010.25\n",
            "Epoch[263] Total loss = 2676673.25\n",
            "Epoch[264] Total loss = 2669351.75\n",
            "Epoch[265] Total loss = 2662046.0\n",
            "Epoch[266] Total loss = 2654755.5\n",
            "Epoch[267] Total loss = 2647480.0\n",
            "Epoch[268] Total loss = 2640219.0\n",
            "Epoch[269] Total loss = 2632972.75\n",
            "Epoch[270] Total loss = 2625741.5\n",
            "Epoch[271] Total loss = 2618524.5\n",
            "Epoch[272] Total loss = 2611322.25\n",
            "Epoch[273] Total loss = 2604134.25\n",
            "Epoch[274] Total loss = 2596960.5\n",
            "Epoch[275] Total loss = 2589801.5\n",
            "Epoch[276] Total loss = 2582657.0\n",
            "Epoch[277] Total loss = 2575526.25\n",
            "Epoch[278] Total loss = 2568409.0\n",
            "Epoch[279] Total loss = 2561305.5\n",
            "Epoch[280] Total loss = 2554216.0\n",
            "Epoch[281] Total loss = 2547138.5\n",
            "Epoch[282] Total loss = 2540074.5\n",
            "Epoch[283] Total loss = 2533024.25\n",
            "Epoch[284] Total loss = 2525985.75\n",
            "Epoch[285] Total loss = 2518960.0\n",
            "Epoch[286] Total loss = 2511947.25\n",
            "Epoch[287] Total loss = 2504947.75\n",
            "Epoch[288] Total loss = 2497962.0\n",
            "Epoch[289] Total loss = 2490989.75\n",
            "Epoch[290] Total loss = 2484030.5\n",
            "Epoch[291] Total loss = 2477083.5\n",
            "Epoch[292] Total loss = 2470149.5\n",
            "Epoch[293] Total loss = 2463228.75\n",
            "Epoch[294] Total loss = 2456322.25\n",
            "Epoch[295] Total loss = 2449429.5\n",
            "Epoch[296] Total loss = 2442551.0\n",
            "Epoch[297] Total loss = 2435685.75\n",
            "Epoch[298] Total loss = 2428833.75\n",
            "Epoch[299] Total loss = 2421994.25\n",
            "Epoch[300] Total loss = 2415168.0\n",
            "Epoch[301] Total loss = 2408352.25\n",
            "Epoch[302] Total loss = 2401549.75\n",
            "Epoch[303] Total loss = 2394759.5\n",
            "Epoch[304] Total loss = 2387981.25\n",
            "Epoch[305] Total loss = 2381217.75\n",
            "Epoch[306] Total loss = 2374465.5\n",
            "Epoch[307] Total loss = 2367726.0\n",
            "Epoch[308] Total loss = 2360999.0\n",
            "Epoch[309] Total loss = 2354284.0\n",
            "Epoch[310] Total loss = 2347581.5\n",
            "Epoch[311] Total loss = 2340891.0\n",
            "Epoch[312] Total loss = 2334214.0\n",
            "Epoch[313] Total loss = 2327549.25\n",
            "Epoch[314] Total loss = 2320896.0\n",
            "Epoch[315] Total loss = 2314255.75\n",
            "Epoch[316] Total loss = 2307629.0\n",
            "Epoch[317] Total loss = 2301012.75\n",
            "Epoch[318] Total loss = 2294409.0\n",
            "Epoch[319] Total loss = 2287817.5\n",
            "Epoch[320] Total loss = 2281238.25\n",
            "Epoch[321] Total loss = 2274670.5\n",
            "Epoch[322] Total loss = 2268115.25\n",
            "Epoch[323] Total loss = 2261570.75\n",
            "Epoch[324] Total loss = 2255038.5\n",
            "Epoch[325] Total loss = 2248519.25\n",
            "Epoch[326] Total loss = 2242012.75\n",
            "Epoch[327] Total loss = 2235519.75\n",
            "Epoch[328] Total loss = 2229039.75\n",
            "Epoch[329] Total loss = 2222572.0\n",
            "Epoch[330] Total loss = 2216116.75\n",
            "Epoch[331] Total loss = 2209674.75\n",
            "Epoch[332] Total loss = 2203244.5\n",
            "Epoch[333] Total loss = 2196826.0\n",
            "Epoch[334] Total loss = 2190420.0\n",
            "Epoch[335] Total loss = 2184026.25\n",
            "Epoch[336] Total loss = 2177645.75\n",
            "Epoch[337] Total loss = 2171277.0\n",
            "Epoch[338] Total loss = 2164921.0\n",
            "Epoch[339] Total loss = 2158577.0\n",
            "Epoch[340] Total loss = 2152245.0\n",
            "Epoch[341] Total loss = 2145925.75\n",
            "Epoch[342] Total loss = 2139618.25\n",
            "Epoch[343] Total loss = 2133324.0\n",
            "Epoch[344] Total loss = 2127042.0\n",
            "Epoch[345] Total loss = 2120772.25\n",
            "Epoch[346] Total loss = 2114514.5\n",
            "Epoch[347] Total loss = 2108268.25\n",
            "Epoch[348] Total loss = 2102034.5\n",
            "Epoch[349] Total loss = 2095812.25\n",
            "Epoch[350] Total loss = 2089602.375\n",
            "Epoch[351] Total loss = 2083404.125\n",
            "Epoch[352] Total loss = 2077218.375\n",
            "Epoch[353] Total loss = 2071045.375\n",
            "Epoch[354] Total loss = 2064884.75\n",
            "Epoch[355] Total loss = 2058737.0\n",
            "Epoch[356] Total loss = 2052602.0\n",
            "Epoch[357] Total loss = 2046480.125\n",
            "Epoch[358] Total loss = 2040370.5\n",
            "Epoch[359] Total loss = 2034273.375\n",
            "Epoch[360] Total loss = 2028188.5\n",
            "Epoch[361] Total loss = 2022117.125\n",
            "Epoch[362] Total loss = 2016059.0\n",
            "Epoch[363] Total loss = 2010013.125\n",
            "Epoch[364] Total loss = 2003979.625\n",
            "Epoch[365] Total loss = 1997959.0\n",
            "Epoch[366] Total loss = 1991949.875\n",
            "Epoch[367] Total loss = 1985953.0\n",
            "Epoch[368] Total loss = 1979968.375\n",
            "Epoch[369] Total loss = 1973996.125\n",
            "Epoch[370] Total loss = 1968036.125\n",
            "Epoch[371] Total loss = 1962089.625\n",
            "Epoch[372] Total loss = 1956156.375\n",
            "Epoch[373] Total loss = 1950236.75\n",
            "Epoch[374] Total loss = 1944330.5\n",
            "Epoch[375] Total loss = 1938437.0\n",
            "Epoch[376] Total loss = 1932556.5\n",
            "Epoch[377] Total loss = 1926690.0\n",
            "Epoch[378] Total loss = 1920836.5\n",
            "Epoch[379] Total loss = 1914995.875\n",
            "Epoch[380] Total loss = 1909168.5\n",
            "Epoch[381] Total loss = 1903354.25\n",
            "Epoch[382] Total loss = 1897553.75\n",
            "Epoch[383] Total loss = 1891766.625\n",
            "Epoch[384] Total loss = 1885993.125\n",
            "Epoch[385] Total loss = 1880233.0\n",
            "Epoch[386] Total loss = 1874486.625\n",
            "Epoch[387] Total loss = 1868753.625\n",
            "Epoch[388] Total loss = 1863034.875\n",
            "Epoch[389] Total loss = 1857330.125\n",
            "Epoch[390] Total loss = 1851638.625\n",
            "Epoch[391] Total loss = 1845960.375\n",
            "Epoch[392] Total loss = 1840296.0\n",
            "Epoch[393] Total loss = 1834646.75\n",
            "Epoch[394] Total loss = 1829011.5\n",
            "Epoch[395] Total loss = 1823390.0\n",
            "Epoch[396] Total loss = 1817782.125\n",
            "Epoch[397] Total loss = 1812189.0\n",
            "Epoch[398] Total loss = 1806610.125\n",
            "Epoch[399] Total loss = 1801045.25\n",
            "Epoch[400] Total loss = 1795494.875\n",
            "Epoch[401] Total loss = 1789959.25\n",
            "Epoch[402] Total loss = 1784437.25\n",
            "Epoch[403] Total loss = 1778929.625\n",
            "Epoch[404] Total loss = 1773436.5\n",
            "Epoch[405] Total loss = 1767957.75\n",
            "Epoch[406] Total loss = 1762493.875\n",
            "Epoch[407] Total loss = 1757044.625\n",
            "Epoch[408] Total loss = 1751610.875\n",
            "Epoch[409] Total loss = 1746192.125\n",
            "Epoch[410] Total loss = 1740788.125\n",
            "Epoch[411] Total loss = 1735398.5\n",
            "Epoch[412] Total loss = 1730023.625\n",
            "Epoch[413] Total loss = 1724663.5\n",
            "Epoch[414] Total loss = 1719318.5\n",
            "Epoch[415] Total loss = 1713988.5\n",
            "Epoch[416] Total loss = 1708673.0\n",
            "Epoch[417] Total loss = 1703373.25\n",
            "Epoch[418] Total loss = 1698088.0\n",
            "Epoch[419] Total loss = 1692817.625\n",
            "Epoch[420] Total loss = 1687562.375\n",
            "Epoch[421] Total loss = 1682322.875\n",
            "Epoch[422] Total loss = 1677098.75\n",
            "Epoch[423] Total loss = 1671890.25\n",
            "Epoch[424] Total loss = 1666696.875\n",
            "Epoch[425] Total loss = 1661519.125\n",
            "Epoch[426] Total loss = 1656357.125\n",
            "Epoch[427] Total loss = 1651210.75\n",
            "Epoch[428] Total loss = 1646080.0\n",
            "Epoch[429] Total loss = 1640965.125\n",
            "Epoch[430] Total loss = 1635865.25\n",
            "Epoch[431] Total loss = 1630780.625\n",
            "Epoch[432] Total loss = 1625711.625\n",
            "Epoch[433] Total loss = 1620658.75\n",
            "Epoch[434] Total loss = 1615622.375\n",
            "Epoch[435] Total loss = 1610601.375\n",
            "Epoch[436] Total loss = 1605596.5\n",
            "Epoch[437] Total loss = 1600607.75\n",
            "Epoch[438] Total loss = 1595634.75\n",
            "Epoch[439] Total loss = 1590678.25\n",
            "Epoch[440] Total loss = 1585737.625\n",
            "Epoch[441] Total loss = 1580812.75\n",
            "Epoch[442] Total loss = 1575903.75\n",
            "Epoch[443] Total loss = 1571011.0\n",
            "Epoch[444] Total loss = 1566134.5\n",
            "Epoch[445] Total loss = 1561274.125\n",
            "Epoch[446] Total loss = 1556430.0\n",
            "Epoch[447] Total loss = 1551602.375\n",
            "Epoch[448] Total loss = 1546791.125\n",
            "Epoch[449] Total loss = 1541996.375\n",
            "Epoch[450] Total loss = 1537217.75\n",
            "Epoch[451] Total loss = 1532455.625\n",
            "Epoch[452] Total loss = 1527710.625\n",
            "Epoch[453] Total loss = 1522981.75\n",
            "Epoch[454] Total loss = 1518269.375\n",
            "Epoch[455] Total loss = 1513573.5\n",
            "Epoch[456] Total loss = 1508894.5\n",
            "Epoch[457] Total loss = 1504231.75\n",
            "Epoch[458] Total loss = 1499585.75\n",
            "Epoch[459] Total loss = 1494956.375\n",
            "Epoch[460] Total loss = 1490343.625\n",
            "Epoch[461] Total loss = 1485747.875\n",
            "Epoch[462] Total loss = 1481168.875\n",
            "Epoch[463] Total loss = 1476606.875\n",
            "Epoch[464] Total loss = 1472061.25\n",
            "Epoch[465] Total loss = 1467532.625\n",
            "Epoch[466] Total loss = 1463020.75\n",
            "Epoch[467] Total loss = 1458525.75\n",
            "Epoch[468] Total loss = 1454047.75\n",
            "Epoch[469] Total loss = 1449586.75\n",
            "Epoch[470] Total loss = 1445142.75\n",
            "Epoch[471] Total loss = 1440715.875\n",
            "Epoch[472] Total loss = 1436306.0\n",
            "Epoch[473] Total loss = 1431913.5\n",
            "Epoch[474] Total loss = 1427538.25\n",
            "Epoch[475] Total loss = 1423179.875\n",
            "Epoch[476] Total loss = 1418839.25\n",
            "Epoch[477] Total loss = 1414516.125\n",
            "Epoch[478] Total loss = 1410209.625\n",
            "Epoch[479] Total loss = 1405920.875\n",
            "Epoch[480] Total loss = 1401648.875\n",
            "Epoch[481] Total loss = 1397394.75\n",
            "Epoch[482] Total loss = 1393158.0\n",
            "Epoch[483] Total loss = 1388938.75\n",
            "Epoch[484] Total loss = 1384736.875\n",
            "Epoch[485] Total loss = 1380552.75\n",
            "Epoch[486] Total loss = 1376385.875\n",
            "Epoch[487] Total loss = 1372236.375\n",
            "Epoch[488] Total loss = 1368104.125\n",
            "Epoch[489] Total loss = 1363989.375\n",
            "Epoch[490] Total loss = 1359892.25\n",
            "Epoch[491] Total loss = 1355812.75\n",
            "Epoch[492] Total loss = 1351751.0\n",
            "Epoch[493] Total loss = 1347706.125\n",
            "Epoch[494] Total loss = 1343679.125\n",
            "Epoch[495] Total loss = 1339668.875\n",
            "Epoch[496] Total loss = 1335676.0\n",
            "Epoch[497] Total loss = 1331700.375\n",
            "Epoch[498] Total loss = 1327742.25\n",
            "Epoch[499] Total loss = 1323801.75\n",
            "Epoch[500] Total loss = 1319878.875\n",
            "Epoch[501] Total loss = 1315974.0\n",
            "Epoch[502] Total loss = 1312086.375\n",
            "Epoch[503] Total loss = 1308216.125\n",
            "Epoch[504] Total loss = 1304363.75\n",
            "Epoch[505] Total loss = 1300528.875\n",
            "Epoch[506] Total loss = 1296711.75\n",
            "Epoch[507] Total loss = 1292912.125\n",
            "Epoch[508] Total loss = 1289129.75\n",
            "Epoch[509] Total loss = 1285365.25\n",
            "Epoch[510] Total loss = 1281618.125\n",
            "Epoch[511] Total loss = 1277888.5\n",
            "Epoch[512] Total loss = 1274176.25\n",
            "Epoch[513] Total loss = 1270480.875\n",
            "Epoch[514] Total loss = 1266802.75\n",
            "Epoch[515] Total loss = 1263142.375\n",
            "Epoch[516] Total loss = 1259498.875\n",
            "Epoch[517] Total loss = 1255872.5\n",
            "Epoch[518] Total loss = 1252263.625\n",
            "Epoch[519] Total loss = 1248671.375\n",
            "Epoch[520] Total loss = 1245096.75\n",
            "Epoch[521] Total loss = 1241539.625\n",
            "Epoch[522] Total loss = 1238000.0\n",
            "Epoch[523] Total loss = 1234477.75\n",
            "Epoch[524] Total loss = 1230972.75\n",
            "Epoch[525] Total loss = 1227485.125\n",
            "Epoch[526] Total loss = 1224014.75\n",
            "Epoch[527] Total loss = 1220561.875\n",
            "Epoch[528] Total loss = 1217126.125\n",
            "Epoch[529] Total loss = 1213707.25\n",
            "Epoch[530] Total loss = 1210305.625\n",
            "Epoch[531] Total loss = 1206921.375\n",
            "Epoch[532] Total loss = 1203553.875\n",
            "Epoch[533] Total loss = 1200203.5\n",
            "Epoch[534] Total loss = 1196869.625\n",
            "Epoch[535] Total loss = 1193553.125\n",
            "Epoch[536] Total loss = 1190253.625\n",
            "Epoch[537] Total loss = 1186971.125\n",
            "Epoch[538] Total loss = 1183705.5\n",
            "Epoch[539] Total loss = 1180456.5\n",
            "Epoch[540] Total loss = 1177224.625\n",
            "Epoch[541] Total loss = 1174009.375\n",
            "Epoch[542] Total loss = 1170810.75\n",
            "Epoch[543] Total loss = 1167628.75\n",
            "Epoch[544] Total loss = 1164463.375\n",
            "Epoch[545] Total loss = 1161314.25\n",
            "Epoch[546] Total loss = 1158181.875\n",
            "Epoch[547] Total loss = 1155066.0\n",
            "Epoch[548] Total loss = 1151966.875\n",
            "Epoch[549] Total loss = 1148884.25\n",
            "Epoch[550] Total loss = 1145818.0\n",
            "Epoch[551] Total loss = 1142768.375\n",
            "Epoch[552] Total loss = 1139734.875\n",
            "Epoch[553] Total loss = 1136718.0\n",
            "Epoch[554] Total loss = 1133717.625\n",
            "Epoch[555] Total loss = 1130733.75\n",
            "Epoch[556] Total loss = 1127765.875\n",
            "Epoch[557] Total loss = 1124814.5\n",
            "Epoch[558] Total loss = 1121879.375\n",
            "Epoch[559] Total loss = 1118960.5\n",
            "Epoch[560] Total loss = 1116057.75\n",
            "Epoch[561] Total loss = 1113171.125\n",
            "Epoch[562] Total loss = 1110300.625\n",
            "Epoch[563] Total loss = 1107446.125\n",
            "Epoch[564] Total loss = 1104607.625\n",
            "Epoch[565] Total loss = 1101784.875\n",
            "Epoch[566] Total loss = 1098978.0\n",
            "Epoch[567] Total loss = 1096186.625\n",
            "Epoch[568] Total loss = 1093411.125\n",
            "Epoch[569] Total loss = 1090651.25\n",
            "Epoch[570] Total loss = 1087906.625\n",
            "Epoch[571] Total loss = 1085177.375\n",
            "Epoch[572] Total loss = 1082464.125\n",
            "Epoch[573] Total loss = 1079766.5\n",
            "Epoch[574] Total loss = 1077084.5\n",
            "Epoch[575] Total loss = 1074417.625\n",
            "Epoch[576] Total loss = 1071766.375\n",
            "Epoch[577] Total loss = 1069129.75\n",
            "Epoch[578] Total loss = 1066509.0\n",
            "Epoch[579] Total loss = 1063903.125\n",
            "Epoch[580] Total loss = 1061312.375\n",
            "Epoch[581] Total loss = 1058737.25\n",
            "Epoch[582] Total loss = 1056176.625\n",
            "Epoch[583] Total loss = 1053631.25\n",
            "Epoch[584] Total loss = 1051100.625\n",
            "Epoch[585] Total loss = 1048584.75\n",
            "Epoch[586] Total loss = 1046083.625\n",
            "Epoch[587] Total loss = 1043596.875\n",
            "Epoch[588] Total loss = 1041124.625\n",
            "Epoch[589] Total loss = 1038666.875\n",
            "Epoch[590] Total loss = 1036223.5625\n",
            "Epoch[591] Total loss = 1033794.5625\n",
            "Epoch[592] Total loss = 1031379.9375\n",
            "Epoch[593] Total loss = 1028979.3125\n",
            "Epoch[594] Total loss = 1026592.5\n",
            "Epoch[595] Total loss = 1024219.5625\n",
            "Epoch[596] Total loss = 1021860.6875\n",
            "Epoch[597] Total loss = 1019515.625\n",
            "Epoch[598] Total loss = 1017184.0\n",
            "Epoch[599] Total loss = 1014866.0\n",
            "Epoch[600] Total loss = 1012561.1875\n",
            "Epoch[601] Total loss = 1010270.5\n",
            "Epoch[602] Total loss = 1007993.0625\n",
            "Epoch[603] Total loss = 1005729.125\n",
            "Epoch[604] Total loss = 1003478.6875\n",
            "Epoch[605] Total loss = 1001241.625\n",
            "Epoch[606] Total loss = 999017.8125\n",
            "Epoch[607] Total loss = 996807.375\n",
            "Epoch[608] Total loss = 994609.9375\n",
            "Epoch[609] Total loss = 992425.8125\n",
            "Epoch[610] Total loss = 990254.625\n",
            "Epoch[611] Total loss = 988096.875\n",
            "Epoch[612] Total loss = 985951.875\n",
            "Epoch[613] Total loss = 983820.125\n",
            "Epoch[614] Total loss = 981701.1875\n",
            "Epoch[615] Total loss = 979595.25\n",
            "Epoch[616] Total loss = 977501.5\n",
            "Epoch[617] Total loss = 975420.375\n",
            "Epoch[618] Total loss = 973351.75\n",
            "Epoch[619] Total loss = 971295.5\n",
            "Epoch[620] Total loss = 969251.6875\n",
            "Epoch[621] Total loss = 967220.125\n",
            "Epoch[622] Total loss = 965200.875\n",
            "Epoch[623] Total loss = 963193.875\n",
            "Epoch[624] Total loss = 961198.75\n",
            "Epoch[625] Total loss = 959215.8125\n",
            "Epoch[626] Total loss = 957244.625\n",
            "Epoch[627] Total loss = 955285.5625\n",
            "Epoch[628] Total loss = 953338.625\n",
            "Epoch[629] Total loss = 951403.0625\n",
            "Epoch[630] Total loss = 949479.5625\n",
            "Epoch[631] Total loss = 947567.75\n",
            "Epoch[632] Total loss = 945667.25\n",
            "Epoch[633] Total loss = 943778.1875\n",
            "Epoch[634] Total loss = 941900.5\n",
            "Epoch[635] Total loss = 940034.3125\n",
            "Epoch[636] Total loss = 938179.0625\n",
            "Epoch[637] Total loss = 936335.0\n",
            "Epoch[638] Total loss = 934501.9375\n",
            "Epoch[639] Total loss = 932679.9375\n",
            "Epoch[640] Total loss = 930869.0\n",
            "Epoch[641] Total loss = 929068.9375\n",
            "Epoch[642] Total loss = 927280.0625\n",
            "Epoch[643] Total loss = 925501.875\n",
            "Epoch[644] Total loss = 923734.4375\n",
            "Epoch[645] Total loss = 921977.8125\n",
            "Epoch[646] Total loss = 920231.8125\n",
            "Epoch[647] Total loss = 918496.0\n",
            "Epoch[648] Total loss = 916770.75\n",
            "Epoch[649] Total loss = 915055.4375\n",
            "Epoch[650] Total loss = 913350.25\n",
            "Epoch[651] Total loss = 911655.3125\n",
            "Epoch[652] Total loss = 909970.5\n",
            "Epoch[653] Total loss = 908295.8125\n",
            "Epoch[654] Total loss = 906631.0625\n",
            "Epoch[655] Total loss = 904976.5625\n",
            "Epoch[656] Total loss = 903331.5625\n",
            "Epoch[657] Total loss = 901696.6875\n",
            "Epoch[658] Total loss = 900071.25\n",
            "Epoch[659] Total loss = 898455.5625\n",
            "Epoch[660] Total loss = 896849.3125\n",
            "Epoch[661] Total loss = 895252.5\n",
            "Epoch[662] Total loss = 893664.9375\n",
            "Epoch[663] Total loss = 892086.875\n",
            "Epoch[664] Total loss = 890518.0\n",
            "Epoch[665] Total loss = 888958.5625\n",
            "Epoch[666] Total loss = 887408.3125\n",
            "Epoch[667] Total loss = 885867.375\n",
            "Epoch[668] Total loss = 884335.3125\n",
            "Epoch[669] Total loss = 882811.9375\n",
            "Epoch[670] Total loss = 881297.4375\n",
            "Epoch[671] Total loss = 879791.6875\n",
            "Epoch[672] Total loss = 878294.8125\n",
            "Epoch[673] Total loss = 876806.625\n",
            "Epoch[674] Total loss = 875327.0625\n",
            "Epoch[675] Total loss = 873856.0\n",
            "Epoch[676] Total loss = 872393.375\n",
            "Epoch[677] Total loss = 870939.125\n",
            "Epoch[678] Total loss = 869493.25\n",
            "Epoch[679] Total loss = 868055.75\n",
            "Epoch[680] Total loss = 866626.25\n",
            "Epoch[681] Total loss = 865204.8125\n",
            "Epoch[682] Total loss = 863791.75\n",
            "Epoch[683] Total loss = 862386.375\n",
            "Epoch[684] Total loss = 860989.1875\n",
            "Epoch[685] Total loss = 859600.0\n",
            "Epoch[686] Total loss = 858218.5\n",
            "Epoch[687] Total loss = 856844.6875\n",
            "Epoch[688] Total loss = 855478.6875\n",
            "Epoch[689] Total loss = 854120.375\n",
            "Epoch[690] Total loss = 852769.4375\n",
            "Epoch[691] Total loss = 851426.125\n",
            "Epoch[692] Total loss = 850090.0625\n",
            "Epoch[693] Total loss = 848761.1875\n",
            "Epoch[694] Total loss = 847439.6875\n",
            "Epoch[695] Total loss = 846125.4375\n",
            "Epoch[696] Total loss = 844818.25\n",
            "Epoch[697] Total loss = 843518.375\n",
            "Epoch[698] Total loss = 842225.5\n",
            "Epoch[699] Total loss = 840939.75\n",
            "Epoch[700] Total loss = 839660.875\n",
            "Epoch[701] Total loss = 838388.9375\n",
            "Epoch[702] Total loss = 837123.75\n",
            "Epoch[703] Total loss = 835865.25\n",
            "Epoch[704] Total loss = 834613.5\n",
            "Epoch[705] Total loss = 833368.3125\n",
            "Epoch[706] Total loss = 832129.8125\n",
            "Epoch[707] Total loss = 830898.0\n",
            "Epoch[708] Total loss = 829672.625\n",
            "Epoch[709] Total loss = 828453.75\n",
            "Epoch[710] Total loss = 827241.4375\n",
            "Epoch[711] Total loss = 826035.3125\n",
            "Epoch[712] Total loss = 824835.875\n",
            "Epoch[713] Total loss = 823642.4375\n",
            "Epoch[714] Total loss = 822455.0\n",
            "Epoch[715] Total loss = 821273.75\n",
            "Epoch[716] Total loss = 820098.4375\n",
            "Epoch[717] Total loss = 818929.0625\n",
            "Epoch[718] Total loss = 817765.625\n",
            "Epoch[719] Total loss = 816608.25\n",
            "Epoch[720] Total loss = 815456.5\n",
            "Epoch[721] Total loss = 814310.8125\n",
            "Epoch[722] Total loss = 813170.5\n",
            "Epoch[723] Total loss = 812036.375\n",
            "Epoch[724] Total loss = 810907.6875\n",
            "Epoch[725] Total loss = 809784.9375\n",
            "Epoch[726] Total loss = 808667.5\n",
            "Epoch[727] Total loss = 807555.6875\n",
            "Epoch[728] Total loss = 806449.5\n",
            "Epoch[729] Total loss = 805348.5\n",
            "Epoch[730] Total loss = 804253.0\n",
            "Epoch[731] Total loss = 803162.8125\n",
            "Epoch[732] Total loss = 802078.0625\n",
            "Epoch[733] Total loss = 800998.25\n",
            "Epoch[734] Total loss = 799924.0625\n",
            "Epoch[735] Total loss = 798854.8125\n",
            "Epoch[736] Total loss = 797790.8125\n",
            "Epoch[737] Total loss = 796731.75\n",
            "Epoch[738] Total loss = 795677.625\n",
            "Epoch[739] Total loss = 794628.5625\n",
            "Epoch[740] Total loss = 793584.25\n",
            "Epoch[741] Total loss = 792545.0625\n",
            "Epoch[742] Total loss = 791510.875\n",
            "Epoch[743] Total loss = 790481.375\n",
            "Epoch[744] Total loss = 789456.6875\n",
            "Epoch[745] Total loss = 788436.6875\n",
            "Epoch[746] Total loss = 787421.375\n",
            "Epoch[747] Total loss = 786410.875\n",
            "Epoch[748] Total loss = 785405.0625\n",
            "Epoch[749] Total loss = 784403.875\n",
            "Epoch[750] Total loss = 783407.125\n",
            "Epoch[751] Total loss = 782415.0625\n",
            "Epoch[752] Total loss = 781427.25\n",
            "Epoch[753] Total loss = 780443.875\n",
            "Epoch[754] Total loss = 779465.0\n",
            "Epoch[755] Total loss = 778490.5625\n",
            "Epoch[756] Total loss = 777520.0625\n",
            "Epoch[757] Total loss = 776553.9375\n",
            "Epoch[758] Total loss = 775592.25\n",
            "Epoch[759] Total loss = 774634.625\n",
            "Epoch[760] Total loss = 773681.125\n",
            "Epoch[761] Total loss = 772731.8125\n",
            "Epoch[762] Total loss = 771786.625\n",
            "Epoch[763] Total loss = 770845.1875\n",
            "Epoch[764] Total loss = 769907.625\n",
            "Epoch[765] Total loss = 768973.8125\n",
            "Epoch[766] Total loss = 768043.9375\n",
            "Epoch[767] Total loss = 767118.0625\n",
            "Epoch[768] Total loss = 766195.75\n",
            "Epoch[769] Total loss = 765277.1875\n",
            "Epoch[770] Total loss = 764362.625\n",
            "Epoch[771] Total loss = 763451.75\n",
            "Epoch[772] Total loss = 762544.375\n",
            "Epoch[773] Total loss = 761640.75\n",
            "Epoch[774] Total loss = 760740.5625\n",
            "Epoch[775] Total loss = 759844.0\n",
            "Epoch[776] Total loss = 758951.0\n",
            "Epoch[777] Total loss = 758061.25\n",
            "Epoch[778] Total loss = 757174.9375\n",
            "Epoch[779] Total loss = 756292.0625\n",
            "Epoch[780] Total loss = 755412.625\n",
            "Epoch[781] Total loss = 754536.5625\n",
            "Epoch[782] Total loss = 753663.75\n",
            "Epoch[783] Total loss = 752794.4375\n",
            "Epoch[784] Total loss = 751928.4375\n",
            "Epoch[785] Total loss = 751065.6875\n",
            "Epoch[786] Total loss = 750206.25\n",
            "Epoch[787] Total loss = 749350.0\n",
            "Epoch[788] Total loss = 748496.6875\n",
            "Epoch[789] Total loss = 747646.6875\n",
            "Epoch[790] Total loss = 746800.0\n",
            "Epoch[791] Total loss = 745956.0\n",
            "Epoch[792] Total loss = 745115.1875\n",
            "Epoch[793] Total loss = 744277.25\n",
            "Epoch[794] Total loss = 743442.3125\n",
            "Epoch[795] Total loss = 742610.25\n",
            "Epoch[796] Total loss = 741780.9375\n",
            "Epoch[797] Total loss = 740954.75\n",
            "Epoch[798] Total loss = 740131.3125\n",
            "Epoch[799] Total loss = 739310.875\n",
            "Epoch[800] Total loss = 738493.1875\n",
            "Epoch[801] Total loss = 737678.0625\n",
            "Epoch[802] Total loss = 736865.875\n",
            "Epoch[803] Total loss = 736056.4375\n",
            "Epoch[804] Total loss = 735249.5625\n",
            "Epoch[805] Total loss = 734445.75\n",
            "Epoch[806] Total loss = 733644.375\n",
            "Epoch[807] Total loss = 732845.8125\n",
            "Epoch[808] Total loss = 732049.875\n",
            "Epoch[809] Total loss = 731256.625\n",
            "Epoch[810] Total loss = 730465.75\n",
            "Epoch[811] Total loss = 729677.5\n",
            "Epoch[812] Total loss = 728891.5625\n",
            "Epoch[813] Total loss = 728108.1875\n",
            "Epoch[814] Total loss = 727327.3125\n",
            "Epoch[815] Total loss = 726549.0625\n",
            "Epoch[816] Total loss = 725773.3125\n",
            "Epoch[817] Total loss = 725000.125\n",
            "Epoch[818] Total loss = 724229.25\n",
            "Epoch[819] Total loss = 723461.0\n",
            "Epoch[820] Total loss = 722695.25\n",
            "Epoch[821] Total loss = 721931.875\n",
            "Epoch[822] Total loss = 721170.75\n",
            "Epoch[823] Total loss = 720411.9375\n",
            "Epoch[824] Total loss = 719655.125\n",
            "Epoch[825] Total loss = 718901.0\n",
            "Epoch[826] Total loss = 718148.75\n",
            "Epoch[827] Total loss = 717398.75\n",
            "Epoch[828] Total loss = 716650.8125\n",
            "Epoch[829] Total loss = 715905.3125\n",
            "Epoch[830] Total loss = 715161.8125\n",
            "Epoch[831] Total loss = 714420.5625\n",
            "Epoch[832] Total loss = 713681.5625\n",
            "Epoch[833] Total loss = 712944.5625\n",
            "Epoch[834] Total loss = 712209.8125\n",
            "Epoch[835] Total loss = 711477.0\n",
            "Epoch[836] Total loss = 710746.375\n",
            "Epoch[837] Total loss = 710017.5625\n",
            "Epoch[838] Total loss = 709290.9375\n",
            "Epoch[839] Total loss = 708566.125\n",
            "Epoch[840] Total loss = 707843.5\n",
            "Epoch[841] Total loss = 707122.5625\n",
            "Epoch[842] Total loss = 706403.8125\n",
            "Epoch[843] Total loss = 705687.1875\n",
            "Epoch[844] Total loss = 704972.5\n",
            "Epoch[845] Total loss = 704259.6875\n",
            "Epoch[846] Total loss = 703548.625\n",
            "Epoch[847] Total loss = 702839.6875\n",
            "Epoch[848] Total loss = 702132.5\n",
            "Epoch[849] Total loss = 701427.1875\n",
            "Epoch[850] Total loss = 700723.75\n",
            "Epoch[851] Total loss = 700022.0\n",
            "Epoch[852] Total loss = 699322.4375\n",
            "Epoch[853] Total loss = 698624.5625\n",
            "Epoch[854] Total loss = 697928.5625\n",
            "Epoch[855] Total loss = 697234.3125\n",
            "Epoch[856] Total loss = 696541.75\n",
            "Epoch[857] Total loss = 695851.0\n",
            "Epoch[858] Total loss = 695161.9375\n",
            "Epoch[859] Total loss = 694474.4375\n",
            "Epoch[860] Total loss = 693788.625\n",
            "Epoch[861] Total loss = 693104.5\n",
            "Epoch[862] Total loss = 692422.0\n",
            "Epoch[863] Total loss = 691741.4375\n",
            "Epoch[864] Total loss = 691062.4375\n",
            "Epoch[865] Total loss = 690384.875\n",
            "Epoch[866] Total loss = 689709.125\n",
            "Epoch[867] Total loss = 689034.8125\n",
            "Epoch[868] Total loss = 688362.1875\n",
            "Epoch[869] Total loss = 687690.9375\n",
            "Epoch[870] Total loss = 687021.1875\n",
            "Epoch[871] Total loss = 686353.125\n",
            "Epoch[872] Total loss = 685686.5\n",
            "Epoch[873] Total loss = 685021.4375\n",
            "Epoch[874] Total loss = 684357.9375\n",
            "Epoch[875] Total loss = 683695.8125\n",
            "Epoch[876] Total loss = 683035.1875\n",
            "Epoch[877] Total loss = 682376.0625\n",
            "Epoch[878] Total loss = 681718.1875\n",
            "Epoch[879] Total loss = 681061.8125\n",
            "Epoch[880] Total loss = 680407.0625\n",
            "Epoch[881] Total loss = 679753.625\n",
            "Epoch[882] Total loss = 679101.625\n",
            "Epoch[883] Total loss = 678451.125\n",
            "Epoch[884] Total loss = 677802.0625\n",
            "Epoch[885] Total loss = 677154.3125\n",
            "Epoch[886] Total loss = 676507.8125\n",
            "Epoch[887] Total loss = 675862.875\n",
            "Epoch[888] Total loss = 675219.0625\n",
            "Epoch[889] Total loss = 674576.5625\n",
            "Epoch[890] Total loss = 673935.5\n",
            "Epoch[891] Total loss = 673295.6875\n",
            "Epoch[892] Total loss = 672657.1875\n",
            "Epoch[893] Total loss = 672020.0\n",
            "Epoch[894] Total loss = 671384.25\n",
            "Epoch[895] Total loss = 670749.625\n",
            "Epoch[896] Total loss = 670116.25\n",
            "Epoch[897] Total loss = 669484.25\n",
            "Epoch[898] Total loss = 668853.375\n",
            "Epoch[899] Total loss = 668223.875\n",
            "Epoch[900] Total loss = 667595.6875\n",
            "Epoch[901] Total loss = 666968.6875\n",
            "Epoch[902] Total loss = 666343.0\n",
            "Epoch[903] Total loss = 665718.375\n",
            "Epoch[904] Total loss = 665094.8125\n",
            "Epoch[905] Total loss = 664472.5625\n",
            "Epoch[906] Total loss = 663851.375\n",
            "Epoch[907] Total loss = 663231.3125\n",
            "Epoch[908] Total loss = 662612.4375\n",
            "Epoch[909] Total loss = 661994.75\n",
            "Epoch[910] Total loss = 661378.1875\n",
            "Epoch[911] Total loss = 660762.9375\n",
            "Epoch[912] Total loss = 660148.5625\n",
            "Epoch[913] Total loss = 659535.4375\n",
            "Epoch[914] Total loss = 658923.4375\n",
            "Epoch[915] Total loss = 658312.5625\n",
            "Epoch[916] Total loss = 657702.6875\n",
            "Epoch[917] Total loss = 657094.0625\n",
            "Epoch[918] Total loss = 656486.4375\n",
            "Epoch[919] Total loss = 655879.9375\n",
            "Epoch[920] Total loss = 655274.5\n",
            "Epoch[921] Total loss = 654670.0625\n",
            "Epoch[922] Total loss = 654066.5\n",
            "Epoch[923] Total loss = 653464.0625\n",
            "Epoch[924] Total loss = 652862.75\n",
            "Epoch[925] Total loss = 652262.3125\n",
            "Epoch[926] Total loss = 651663.0\n",
            "Epoch[927] Total loss = 651064.5625\n",
            "Epoch[928] Total loss = 650467.125\n",
            "Epoch[929] Total loss = 649870.6875\n",
            "Epoch[930] Total loss = 649275.3125\n",
            "Epoch[931] Total loss = 648681.0\n",
            "Epoch[932] Total loss = 648087.5\n",
            "Epoch[933] Total loss = 647495.0625\n",
            "Epoch[934] Total loss = 646903.5625\n",
            "Epoch[935] Total loss = 646313.0625\n",
            "Epoch[936] Total loss = 645723.5\n",
            "Epoch[937] Total loss = 645134.9375\n",
            "Epoch[938] Total loss = 644547.375\n",
            "Epoch[939] Total loss = 643960.625\n",
            "Epoch[940] Total loss = 643375.0625\n",
            "Epoch[941] Total loss = 642790.25\n",
            "Epoch[942] Total loss = 642206.375\n",
            "Epoch[943] Total loss = 641623.4375\n",
            "Epoch[944] Total loss = 641041.4375\n",
            "Epoch[945] Total loss = 640460.375\n",
            "Epoch[946] Total loss = 639880.125\n",
            "Epoch[947] Total loss = 639300.9375\n",
            "Epoch[948] Total loss = 638722.5625\n",
            "Epoch[949] Total loss = 638145.125\n",
            "Epoch[950] Total loss = 637568.5\n",
            "Epoch[951] Total loss = 636992.875\n",
            "Epoch[952] Total loss = 636418.1875\n",
            "Epoch[953] Total loss = 635844.375\n",
            "Epoch[954] Total loss = 635271.5\n",
            "Epoch[955] Total loss = 634699.5\n",
            "Epoch[956] Total loss = 634128.5\n",
            "Epoch[957] Total loss = 633558.1875\n",
            "Epoch[958] Total loss = 632988.875\n",
            "Epoch[959] Total loss = 632420.25\n",
            "Epoch[960] Total loss = 631852.5625\n",
            "Epoch[961] Total loss = 631285.5\n",
            "Epoch[962] Total loss = 630719.3125\n",
            "Epoch[963] Total loss = 630153.875\n",
            "Epoch[964] Total loss = 629589.4375\n",
            "Epoch[965] Total loss = 629025.8125\n",
            "Epoch[966] Total loss = 628463.0625\n",
            "Epoch[967] Total loss = 627901.125\n",
            "Epoch[968] Total loss = 627339.9375\n",
            "Epoch[969] Total loss = 626779.625\n",
            "Epoch[970] Total loss = 626220.0625\n",
            "Epoch[971] Total loss = 625661.3125\n",
            "Epoch[972] Total loss = 625103.4375\n",
            "Epoch[973] Total loss = 624546.25\n",
            "Epoch[974] Total loss = 623989.8125\n",
            "Epoch[975] Total loss = 623434.25\n",
            "Epoch[976] Total loss = 622879.3125\n",
            "Epoch[977] Total loss = 622325.1875\n",
            "Epoch[978] Total loss = 621772.0625\n",
            "Epoch[979] Total loss = 621219.6875\n",
            "Epoch[980] Total loss = 620668.0625\n",
            "Epoch[981] Total loss = 620117.125\n",
            "Epoch[982] Total loss = 619566.9375\n",
            "Epoch[983] Total loss = 619017.4375\n",
            "Epoch[984] Total loss = 618468.625\n",
            "Epoch[985] Total loss = 617920.8125\n",
            "Epoch[986] Total loss = 617373.5625\n",
            "Epoch[987] Total loss = 616827.25\n",
            "Epoch[988] Total loss = 616281.6875\n",
            "Epoch[989] Total loss = 615736.9375\n",
            "Epoch[990] Total loss = 615192.875\n",
            "Epoch[991] Total loss = 614649.5625\n",
            "Epoch[992] Total loss = 614107.125\n",
            "Epoch[993] Total loss = 613565.3125\n",
            "Epoch[994] Total loss = 613024.25\n",
            "Epoch[995] Total loss = 612483.75\n",
            "Epoch[996] Total loss = 611944.1875\n",
            "Epoch[997] Total loss = 611405.25\n",
            "Epoch[998] Total loss = 610867.0625\n",
            "Epoch[999] Total loss = 610329.5\n",
            "Epoch[0] Total loss = 7492126.0\n",
            "Epoch[1] Total loss = 7059967.5\n",
            "Epoch[2] Total loss = 6602221.0\n",
            "Epoch[3] Total loss = 6104874.5\n",
            "Epoch[4] Total loss = 5599588.0\n",
            "Epoch[5] Total loss = 5103228.0\n",
            "Epoch[6] Total loss = 4637942.0\n",
            "Epoch[7] Total loss = 4224406.0\n",
            "Epoch[8] Total loss = 3870255.75\n",
            "Epoch[9] Total loss = 3566849.25\n",
            "Epoch[10] Total loss = 3299120.75\n",
            "Epoch[11] Total loss = 3056401.75\n",
            "Epoch[12] Total loss = 2835269.25\n",
            "Epoch[13] Total loss = 2636992.5\n",
            "Epoch[14] Total loss = 2461986.75\n",
            "Epoch[15] Total loss = 2309059.0\n",
            "Epoch[16] Total loss = 2176071.5\n",
            "Epoch[17] Total loss = 2059540.75\n",
            "Epoch[18] Total loss = 1956246.375\n",
            "Epoch[19] Total loss = 1863496.0\n",
            "Epoch[20] Total loss = 1778859.25\n",
            "Epoch[21] Total loss = 1700803.75\n",
            "Epoch[22] Total loss = 1628207.5\n",
            "Epoch[23] Total loss = 1560088.375\n",
            "Epoch[24] Total loss = 1495685.75\n",
            "Epoch[25] Total loss = 1434609.75\n",
            "Epoch[26] Total loss = 1376397.25\n",
            "Epoch[27] Total loss = 1320970.375\n",
            "Epoch[28] Total loss = 1268125.625\n",
            "Epoch[29] Total loss = 1217894.75\n",
            "Epoch[30] Total loss = 1170121.875\n",
            "Epoch[31] Total loss = 1124736.5\n",
            "Epoch[32] Total loss = 1081639.125\n",
            "Epoch[33] Total loss = 1040810.625\n",
            "Epoch[34] Total loss = 1002129.8125\n",
            "Epoch[35] Total loss = 965462.0625\n",
            "Epoch[36] Total loss = 930684.25\n",
            "Epoch[37] Total loss = 897670.0625\n",
            "Epoch[38] Total loss = 866337.3125\n",
            "Epoch[39] Total loss = 836536.4375\n",
            "Epoch[40] Total loss = 808204.0\n",
            "Epoch[41] Total loss = 781251.3125\n",
            "Epoch[42] Total loss = 755508.0\n",
            "Epoch[43] Total loss = 730911.5625\n",
            "Epoch[44] Total loss = 707372.0625\n",
            "Epoch[45] Total loss = 684819.8125\n",
            "Epoch[46] Total loss = 663209.375\n",
            "Epoch[47] Total loss = 642510.3125\n",
            "Epoch[48] Total loss = 622646.5\n",
            "Epoch[49] Total loss = 603571.1875\n",
            "Epoch[50] Total loss = 585249.4375\n",
            "Epoch[51] Total loss = 567634.125\n",
            "Epoch[52] Total loss = 550720.1875\n",
            "Epoch[53] Total loss = 534484.0625\n",
            "Epoch[54] Total loss = 518889.65625\n",
            "Epoch[55] Total loss = 503901.03125\n",
            "Epoch[56] Total loss = 489510.0\n",
            "Epoch[57] Total loss = 475672.96875\n",
            "Epoch[58] Total loss = 462363.71875\n",
            "Epoch[59] Total loss = 449582.1875\n",
            "Epoch[60] Total loss = 437308.28125\n",
            "Epoch[61] Total loss = 425532.46875\n",
            "Epoch[62] Total loss = 414239.4375\n",
            "Epoch[63] Total loss = 403399.09375\n",
            "Epoch[64] Total loss = 392983.25\n",
            "Epoch[65] Total loss = 382985.09375\n",
            "Epoch[66] Total loss = 373396.59375\n",
            "Epoch[67] Total loss = 364199.125\n",
            "Epoch[68] Total loss = 355370.4375\n",
            "Epoch[69] Total loss = 346898.21875\n",
            "Epoch[70] Total loss = 338771.9375\n",
            "Epoch[71] Total loss = 330979.90625\n",
            "Epoch[72] Total loss = 323505.25\n",
            "Epoch[73] Total loss = 316321.90625\n",
            "Epoch[74] Total loss = 309427.875\n",
            "Epoch[75] Total loss = 302818.84375\n",
            "Epoch[76] Total loss = 296475.4375\n",
            "Epoch[77] Total loss = 290385.46875\n",
            "Epoch[78] Total loss = 284537.15625\n",
            "Epoch[79] Total loss = 278925.375\n",
            "Epoch[80] Total loss = 273541.84375\n",
            "Epoch[81] Total loss = 268369.9375\n",
            "Epoch[82] Total loss = 263401.8125\n",
            "Epoch[83] Total loss = 258620.09375\n",
            "Epoch[84] Total loss = 254022.875\n",
            "Epoch[85] Total loss = 249597.265625\n",
            "Epoch[86] Total loss = 245335.359375\n",
            "Epoch[87] Total loss = 241232.828125\n",
            "Epoch[88] Total loss = 237283.59375\n",
            "Epoch[89] Total loss = 233477.984375\n",
            "Epoch[90] Total loss = 229805.078125\n",
            "Epoch[91] Total loss = 226258.65625\n",
            "Epoch[92] Total loss = 222836.90625\n",
            "Epoch[93] Total loss = 219535.359375\n",
            "Epoch[94] Total loss = 216345.46875\n",
            "Epoch[95] Total loss = 213259.125\n",
            "Epoch[96] Total loss = 210272.203125\n",
            "Epoch[97] Total loss = 207380.203125\n",
            "Epoch[98] Total loss = 204580.1875\n",
            "Epoch[99] Total loss = 201866.96875\n",
            "Epoch[100] Total loss = 199233.890625\n",
            "Epoch[101] Total loss = 196679.578125\n",
            "Epoch[102] Total loss = 194199.03125\n",
            "Epoch[103] Total loss = 191786.75\n",
            "Epoch[104] Total loss = 189441.265625\n",
            "Epoch[105] Total loss = 187162.359375\n",
            "Epoch[106] Total loss = 184945.59375\n",
            "Epoch[107] Total loss = 182790.28125\n",
            "Epoch[108] Total loss = 180692.421875\n",
            "Epoch[109] Total loss = 178648.5625\n",
            "Epoch[110] Total loss = 176657.75\n",
            "Epoch[111] Total loss = 174716.140625\n",
            "Epoch[112] Total loss = 172820.28125\n",
            "Epoch[113] Total loss = 170969.8125\n",
            "Epoch[114] Total loss = 169164.6875\n",
            "Epoch[115] Total loss = 167400.0625\n",
            "Epoch[116] Total loss = 165674.359375\n",
            "Epoch[117] Total loss = 163986.671875\n",
            "Epoch[118] Total loss = 162336.953125\n",
            "Epoch[119] Total loss = 160723.171875\n",
            "Epoch[120] Total loss = 159145.140625\n",
            "Epoch[121] Total loss = 157600.546875\n",
            "Epoch[122] Total loss = 156088.984375\n",
            "Epoch[123] Total loss = 154608.625\n",
            "Epoch[124] Total loss = 153157.8125\n",
            "Epoch[125] Total loss = 151736.1875\n",
            "Epoch[126] Total loss = 150343.0625\n",
            "Epoch[127] Total loss = 148978.53125\n",
            "Epoch[128] Total loss = 147641.828125\n",
            "Epoch[129] Total loss = 146330.609375\n",
            "Epoch[130] Total loss = 145044.03125\n",
            "Epoch[131] Total loss = 143783.25\n",
            "Epoch[132] Total loss = 142546.859375\n",
            "Epoch[133] Total loss = 141333.265625\n",
            "Epoch[134] Total loss = 140141.203125\n",
            "Epoch[135] Total loss = 138970.484375\n",
            "Epoch[136] Total loss = 137821.390625\n",
            "Epoch[137] Total loss = 136692.34375\n",
            "Epoch[138] Total loss = 135583.6875\n",
            "Epoch[139] Total loss = 134494.515625\n",
            "Epoch[140] Total loss = 133424.078125\n",
            "Epoch[141] Total loss = 132373.40625\n",
            "Epoch[142] Total loss = 131340.828125\n",
            "Epoch[143] Total loss = 130326.109375\n",
            "Epoch[144] Total loss = 129328.5625\n",
            "Epoch[145] Total loss = 128347.3671875\n",
            "Epoch[146] Total loss = 127382.4140625\n",
            "Epoch[147] Total loss = 126432.7421875\n",
            "Epoch[148] Total loss = 125499.1640625\n",
            "Epoch[149] Total loss = 124580.8125\n",
            "Epoch[150] Total loss = 123676.0625\n",
            "Epoch[151] Total loss = 122784.9140625\n",
            "Epoch[152] Total loss = 121908.6015625\n",
            "Epoch[153] Total loss = 121046.6328125\n",
            "Epoch[154] Total loss = 120197.234375\n",
            "Epoch[155] Total loss = 119360.484375\n",
            "Epoch[156] Total loss = 118535.765625\n",
            "Epoch[157] Total loss = 117724.640625\n",
            "Epoch[158] Total loss = 116926.5078125\n",
            "Epoch[159] Total loss = 116140.4765625\n",
            "Epoch[160] Total loss = 115366.0390625\n",
            "Epoch[161] Total loss = 114602.8671875\n",
            "Epoch[162] Total loss = 113851.2421875\n",
            "Epoch[163] Total loss = 113111.1015625\n",
            "Epoch[164] Total loss = 112381.796875\n",
            "Epoch[165] Total loss = 111663.0546875\n",
            "Epoch[166] Total loss = 110954.640625\n",
            "Epoch[167] Total loss = 110256.3671875\n",
            "Epoch[168] Total loss = 109567.5234375\n",
            "Epoch[169] Total loss = 108888.390625\n",
            "Epoch[170] Total loss = 108217.9765625\n",
            "Epoch[171] Total loss = 107557.2109375\n",
            "Epoch[172] Total loss = 106905.3046875\n",
            "Epoch[173] Total loss = 106262.7421875\n",
            "Epoch[174] Total loss = 105628.8671875\n",
            "Epoch[175] Total loss = 105003.734375\n",
            "Epoch[176] Total loss = 104386.4765625\n",
            "Epoch[177] Total loss = 103777.609375\n",
            "Epoch[178] Total loss = 103176.7421875\n",
            "Epoch[179] Total loss = 102583.8046875\n",
            "Epoch[180] Total loss = 101998.265625\n",
            "Epoch[181] Total loss = 101420.7890625\n",
            "Epoch[182] Total loss = 100850.546875\n",
            "Epoch[183] Total loss = 100287.0703125\n",
            "Epoch[184] Total loss = 99731.3359375\n",
            "Epoch[185] Total loss = 99182.34375\n",
            "Epoch[186] Total loss = 98640.546875\n",
            "Epoch[187] Total loss = 98105.65625\n",
            "Epoch[188] Total loss = 97577.8515625\n",
            "Epoch[189] Total loss = 97056.2734375\n",
            "Epoch[190] Total loss = 96540.5625\n",
            "Epoch[191] Total loss = 96031.6171875\n",
            "Epoch[192] Total loss = 95528.5625\n",
            "Epoch[193] Total loss = 95031.4375\n",
            "Epoch[194] Total loss = 94540.5703125\n",
            "Epoch[195] Total loss = 94055.71875\n",
            "Epoch[196] Total loss = 93576.8046875\n",
            "Epoch[197] Total loss = 93103.671875\n",
            "Epoch[198] Total loss = 92635.984375\n",
            "Epoch[199] Total loss = 92173.59375\n",
            "Epoch[200] Total loss = 91716.71875\n",
            "Epoch[201] Total loss = 91265.3359375\n",
            "Epoch[202] Total loss = 90819.59375\n",
            "Epoch[203] Total loss = 90378.9921875\n",
            "Epoch[204] Total loss = 89943.6015625\n",
            "Epoch[205] Total loss = 89513.390625\n",
            "Epoch[206] Total loss = 89087.6953125\n",
            "Epoch[207] Total loss = 88666.84375\n",
            "Epoch[208] Total loss = 88250.7578125\n",
            "Epoch[209] Total loss = 87839.4453125\n",
            "Epoch[210] Total loss = 87432.5546875\n",
            "Epoch[211] Total loss = 87030.1328125\n",
            "Epoch[212] Total loss = 86632.2421875\n",
            "Epoch[213] Total loss = 86238.7109375\n",
            "Epoch[214] Total loss = 85849.8671875\n",
            "Epoch[215] Total loss = 85464.921875\n",
            "Epoch[216] Total loss = 85084.0546875\n",
            "Epoch[217] Total loss = 84707.5703125\n",
            "Epoch[218] Total loss = 84334.7734375\n",
            "Epoch[219] Total loss = 83965.765625\n",
            "Epoch[220] Total loss = 83600.7265625\n",
            "Epoch[221] Total loss = 83239.84375\n",
            "Epoch[222] Total loss = 82883.0703125\n",
            "Epoch[223] Total loss = 82530.25\n",
            "Epoch[224] Total loss = 82181.3203125\n",
            "Epoch[225] Total loss = 81835.921875\n",
            "Epoch[226] Total loss = 81494.09375\n",
            "Epoch[227] Total loss = 81155.6875\n",
            "Epoch[228] Total loss = 80820.859375\n",
            "Epoch[229] Total loss = 80488.9921875\n",
            "Epoch[230] Total loss = 80160.6328125\n",
            "Epoch[231] Total loss = 79835.75\n",
            "Epoch[232] Total loss = 79514.0546875\n",
            "Epoch[233] Total loss = 79195.796875\n",
            "Epoch[234] Total loss = 78881.1640625\n",
            "Epoch[235] Total loss = 78569.6171875\n",
            "Epoch[236] Total loss = 78261.1484375\n",
            "Epoch[237] Total loss = 77955.796875\n",
            "Epoch[238] Total loss = 77653.65625\n",
            "Epoch[239] Total loss = 77354.5\n",
            "Epoch[240] Total loss = 77058.6015625\n",
            "Epoch[241] Total loss = 76765.671875\n",
            "Epoch[242] Total loss = 76475.59375\n",
            "Epoch[243] Total loss = 76188.3203125\n",
            "Epoch[244] Total loss = 75903.8515625\n",
            "Epoch[245] Total loss = 75622.2734375\n",
            "Epoch[246] Total loss = 75343.6484375\n",
            "Epoch[247] Total loss = 75067.5703125\n",
            "Epoch[248] Total loss = 74794.3203125\n",
            "Epoch[249] Total loss = 74523.65625\n",
            "Epoch[250] Total loss = 74255.78125\n",
            "Epoch[251] Total loss = 73990.6171875\n",
            "Epoch[252] Total loss = 73728.1796875\n",
            "Epoch[253] Total loss = 73468.3828125\n",
            "Epoch[254] Total loss = 73210.921875\n",
            "Epoch[255] Total loss = 72956.1484375\n",
            "Epoch[256] Total loss = 72703.796875\n",
            "Epoch[257] Total loss = 72453.921875\n",
            "Epoch[258] Total loss = 72206.3671875\n",
            "Epoch[259] Total loss = 71961.1875\n",
            "Epoch[260] Total loss = 71718.4609375\n",
            "Epoch[261] Total loss = 71477.921875\n",
            "Epoch[262] Total loss = 71239.78125\n",
            "Epoch[263] Total loss = 71003.6953125\n",
            "Epoch[264] Total loss = 70769.8828125\n",
            "Epoch[265] Total loss = 70538.1640625\n",
            "Epoch[266] Total loss = 70308.609375\n",
            "Epoch[267] Total loss = 70081.2890625\n",
            "Epoch[268] Total loss = 69856.15625\n",
            "Epoch[269] Total loss = 69633.0078125\n",
            "Epoch[270] Total loss = 69411.8828125\n",
            "Epoch[271] Total loss = 69192.8515625\n",
            "Epoch[272] Total loss = 68975.7734375\n",
            "Epoch[273] Total loss = 68760.75\n",
            "Epoch[274] Total loss = 68547.6484375\n",
            "Epoch[275] Total loss = 68336.2890625\n",
            "Epoch[276] Total loss = 68126.9453125\n",
            "Epoch[277] Total loss = 67919.484375\n",
            "Epoch[278] Total loss = 67713.8359375\n",
            "Epoch[279] Total loss = 67509.6015625\n",
            "Epoch[280] Total loss = 67307.453125\n",
            "Epoch[281] Total loss = 67107.0078125\n",
            "Epoch[282] Total loss = 66908.2734375\n",
            "Epoch[283] Total loss = 66711.46875\n",
            "Epoch[284] Total loss = 66516.2421875\n",
            "Epoch[285] Total loss = 66322.90625\n",
            "Epoch[286] Total loss = 66130.984375\n",
            "Epoch[287] Total loss = 65940.9140625\n",
            "Epoch[288] Total loss = 65752.3671875\n",
            "Epoch[289] Total loss = 65565.421875\n",
            "Epoch[290] Total loss = 65380.0\n",
            "Epoch[291] Total loss = 65196.2421875\n",
            "Epoch[292] Total loss = 65014.1484375\n",
            "Epoch[293] Total loss = 64833.515625\n",
            "Epoch[294] Total loss = 64654.44140625\n",
            "Epoch[295] Total loss = 64476.80078125\n",
            "Epoch[296] Total loss = 64300.86328125\n",
            "Epoch[297] Total loss = 64126.34765625\n",
            "Epoch[298] Total loss = 63953.265625\n",
            "Epoch[299] Total loss = 63781.73828125\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://889cdf3423a3ba104b.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}